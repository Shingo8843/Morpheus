{"version":3,"file":"197.index.js","mappings":"qHACO,SAASA,EAAsBC,EAAQC,EAAOC,EAAY,EAAGC,GAChE,GAAc,IAAVF,EACA,MAAM,OAAY,uBAEtB,MAAMG,EAAiB,IAAIC,IACrBC,EAAwB,IAAID,IAC5BE,EAAaP,EAAOQ,OAC1B,IAAI,IAAIC,EAAI,EAAGA,EAAIF,EAAYE,IAAI,CAC/B,MAAMC,EAAMV,EAAOS,GACbE,EAAgBD,EAAIF,OAC1B,IAAI,IAAII,EAAI,EAAGA,EAAID,EAAeC,IAAI,CAClC,MAAOC,EAAOC,GAASJ,EAAIE,GACrBG,EAAaD,EAAQb,EACrBe,EAAWZ,EAAea,IAAIJ,QACnBK,IAAbF,GACAZ,EAAee,IAAIN,EAAkB,IAAXG,EAAiBD,GAC3CT,EAAsBa,IAAIN,EAAOP,EAAsBW,IAAIJ,GAAS,KAEpET,EAAee,IAAIN,EAAOE,GAC1BT,EAAsBa,IAAIN,EAAO,GAEzC,CACJ,CACA,MAAMO,EAAc,GACpB,IAAK,MAAMC,KAAmBjB,EAAekB,UACzCF,EAAYG,KAAKF,GAErB,MAAMG,EAAUJ,EAAYK,MAAK,CAACC,EAAGC,IAAIA,EAAE,GAAKD,EAAE,KAGlD,GAAkB,IAAdxB,EACA,OAAOsB,EAGX,MAAMI,EAAaJ,EAAQhB,OACrBqB,EAAqB,GAC3B,IAAK,MAAMC,KAA2BxB,EAAsBgB,UACxDO,EAAmBN,KAAKO,GAK5B,MAAMC,EAAmBF,EAAmBJ,MAAK,CAACC,EAAGC,IAAIA,EAAE,GAAKD,EAAE,KAClE,IAAIM,EACJ,IAAI,IAAIvB,EAAI,EAAGA,EAAImB,GACXG,EAAiBtB,GAAG,KAAON,EADJM,IAEvBuB,EAA2BvB,EAMnC,QAAwC,IAA7BuB,EAA0C,CACjD,GAAkB,IAAd9B,EACA,MAAO,GAEX8B,EAA2B,CAC/B,CAEA,GAAkB,IAAd9B,EACA,OAAOsB,EAAQS,MAAM,EAAGD,EAA2B,GAKvD,MAAME,EAAkBF,EAA2BG,KAAKC,KAAiB,IAAZlC,GAAmBsB,EAAQhB,OAASwB,GAA4B,KAC7H,OAAOR,EAAQS,MAAM,EAAGT,EAAQhB,OAAS0B,EAC7C,CACO,SAASG,EAAKC,EAAIC,EAAeC,EAAWC,EAAaC,EAAoBC,GAChF,MAAM,EAAEC,EAAE,EAAEjB,EAAE,EAAEkB,GAAOF,EAEvB,OADYR,KAAKW,IAAI,GAAKN,EAAYD,EAAgB,KAAQA,EAAgB,MAChEM,EAAIP,GAAMM,EAAI,KAAON,EAAKM,GAAK,EAAIjB,EAAIA,EAAIc,EAAcC,GAC3E,C,iBCzEO,SAASK,EAAaC,EAAQC,GACjC,IAAIC,EAAY,EAChB,IAAI,IAAIzC,EAAI,EAAGA,EAAIwC,EAAcxC,IAC7ByC,GAAaF,EAAOvC,GAAKuC,EAAOvC,GAEpC,OAAO0B,KAAKgB,KAAKD,EACrB,CAEO,SAASE,EAAmBC,EAAcC,EAAS9C,EAAQN,EAAY,IAC1E,MAAMqD,EAAkBR,EAAaM,EAAc7C,GAC7CgD,EAAiB,GACvB,IAAK,MAAOC,GAAWP,EAAWF,MAAYU,OAAOpC,QAAQgC,GAAS,CAClE,IAAIK,EAAa,EACjB,IAAI,IAAIlD,EAAI,EAAGA,EAAID,EAAQC,IACvBkD,GAAcN,EAAa5C,GAAKuC,EAAOvC,GAE3C,MAAMmD,EAAaD,GAAcJ,EAAkBL,GAC/CU,GAAc1D,GACdsD,EAAejC,KAAK,CAChBkC,EACAG,GAGZ,CACA,OAAOJ,EAAe/B,MAAK,CAACC,EAAGC,IAAIA,EAAE,GAAKD,EAAE,IAChD,C,kFCvBA,SAASmC,EAAiBC,EAAQ,OAAQpC,EAAGC,GACzC,MAA4B,QAAxBmC,EAAMC,cACCrC,EAAE,GAAKC,EAAE,GAETA,EAAE,GAAKD,EAAE,EAExB,CACOsC,eAAeC,EAAUC,EAAO1C,EAAS2C,GAC5C,MAAMC,EAAS,CAAC,EACVC,EAAS7C,EAAQ8C,KAAI,EAAEC,KAAMA,IAC7BC,QAAgBN,EAAMO,eAAeC,YAAYR,EAAMS,KAAKC,KAAMP,GAClEQ,EAAYnB,OAAOoB,KAAKX,GACxBY,QAAmBb,EAAMc,MAAMC,iCAAiCf,EAAMS,KAAKK,OACjF,IAAK,MAAME,KAASL,EAAU,CAC1B,IAAIM,EAAS,CAAC,EAGd,GAA0B,WAAtBJ,EAAWG,GAAqB,CAChC,MAAM,OAAEE,GAAYjB,EAAae,GAC3BG,EAAM,GACZ,IAAK,MAAMC,KAASF,EAChBC,EAAI9D,KAAK,CACL,GAAG+D,EAAMC,QAAQD,EAAME,KACvB,IAGRL,EAASzB,OAAO+B,YAAYJ,EAChC,CACAjB,EAAOc,GAAS,CACZQ,MAAO,EACPP,SAER,CACA,MAAMQ,EAAgBnB,EAAQhE,OAC9B,IAAI,IAAIC,EAAI,EAAGA,EAAIkF,EAAelF,IAAI,CAClC,MAAMmF,EAAMpB,EAAQ/D,GACpB,IAAK,MAAMyE,KAASL,EAAU,CAC1B,MAAMgB,EAAaX,EAAMY,SAAS,WAAa,QAAUF,EAAKV,GAASU,EAAIV,GACrEa,EAAehB,EAAWG,GAChC,OAAOa,GACH,IAAK,SAGGC,EADe7B,EAAae,GAAOE,OACNhB,EAAOc,GAAOC,OAAQU,GACnD,MAER,IAAK,WACD,CACI,MAAMI,EAAwB,IAAIC,IAC5Bd,EAASjB,EAAae,GAAOE,OACnC,IAAK,MAAMe,KAAKN,EACZG,EAAqBZ,EAAQhB,EAAOc,GAAOC,OAAQgB,EAAGF,GAE1D,KACJ,CACJ,IAAK,UACL,IAAK,OACL,IAAK,SAEGG,EAAkChC,EAAOc,GAAOC,OAAQU,EAAYE,GACpE,MAER,IAAK,YACL,IAAK,SACL,IAAK,WACD,CACI,MAAME,EAAwB,IAAIC,IAC5BG,EAA6B,cAAjBN,EAA+B,UAAY,SAC7D,IAAK,MAAMI,KAAKN,EACZO,EAAkChC,EAAOc,GAAOC,OAAQgB,EAAGE,EAAWJ,GAE1E,KACJ,CACJ,QACI,MAAM,OAAY,sBAAuBF,GAErD,CACJ,CACA,IAAK,MAAMb,KAASL,EAIhB,GAFAT,EAAOc,GAAOQ,MAAQhC,OAAOoB,KAAKV,EAAOc,GAAOC,QAAQ3E,OAE9B,WAAtBuE,EAAWG,GAAqB,CAChC,MAAMoB,EAAwBnC,EAC9BC,EAAOc,GAAOC,OAASzB,OAAO+B,YAAY/B,OAAOpC,QAAQ8C,EAAOc,GAAOC,QAAQ1D,MAAK,CAACC,EAAGC,IAAIkC,EAAiByC,EAAsB7E,KAAMC,EAAGC,KAAIM,MAAMqE,EAAsBC,QAAU,EAAGD,EAAsBE,OAAS,IAC5N,CAEJ,OAAOpC,CACX,CACA,SAAS4B,EAAqBZ,EAAQD,EAAQU,EAAYI,GACtD,IAAK,MAAMX,KAASF,EAAO,CACvB,MAAMqB,EAAQ,GAAGnB,EAAMC,QAAQD,EAAME,KACjCS,GAAyBA,EAAsBS,IAAID,IAGnDZ,GAAcP,EAAMC,MAAQM,GAAcP,EAAME,UAC1BtE,IAAlBiE,EAAOsB,GACPtB,EAAOsB,GAAS,GAEhBtB,EAAOsB,KACHR,GACAA,EAAsBU,IAAIF,IAI1C,CACJ,CACA,SAASL,EAAkCjB,EAAQU,EAAYE,EAAcE,GAEzE,MAAMQ,GAASZ,aAA+C,EAASA,EAAWe,cAAiC,YAAjBb,EAA6B,QAAU,IACrIE,GAAyBA,EAAsBS,IAAID,KAGvDtB,EAAOsB,IAAUtB,EAAOsB,IAAU,GAAK,EACnCR,GACAA,EAAsBU,IAAIF,GAElC,C,iBCvHO,SAASI,EAAqBC,EAAUC,GAC3C,MAAMzC,EAAM,IAAIjE,IACV2G,EAAS,GACf,IAAK,MAAMzC,KAAMuC,EACbxC,EAAInD,IAAIoD,GAAI,GAEhB,IAAK,MAAOA,EAAIzD,KAAUiG,EAClBzC,EAAIoC,IAAInC,KACRyC,EAAOzF,KAAK,CACRgD,EACAzD,IAEJwD,EAAI2C,OAAO1C,IAGnB,OAAOyC,CACX,C,mFCbA,MAAME,EAAiB,CACnBC,QAAS,CAACC,EAAGC,EAAKC,EAAKtC,KACnBqC,EAAIrC,GAASsC,EACND,GAEXE,gBAAkB/G,GAASgH,MAAMjC,KAAK,CAC9B/E,YAGNiH,EAAgB,CAClB,SACA,SACA,WAEGzD,eAAe0D,EAAUxD,EAAO1C,EAASmG,GAC5C,MAAM5C,EAAa4C,EAAQ5C,WACrB6C,EAAmB7C,EAAWvE,OAC9BqH,QAAyB3D,EAAMc,MAAMC,iCAAiCf,EAAMS,KAAKK,OACvF,IAAI,IAAIvE,EAAI,EAAGA,EAAImH,EAAkBnH,IAAI,CACrC,MAAMqH,EAAW/C,EAAWtE,GAC5B,QAA0C,IAA/BoH,EAAiBC,GACxB,MAAM,OAAY,4BAA6BA,GAEnD,IAAKL,EAAc3B,SAAS+B,EAAiBC,IACzC,MAAM,OAAY,4BAA6BA,EAAUL,EAAcM,KAAK,MAAOF,EAAiBC,GAE5G,CACA,MAAMzD,EAAS7C,EAAQ8C,KAAI,EAAEC,MAAM,QAA4BL,EAAM8D,wBAAyBzD,KAGxFC,QAAgBN,EAAMO,eAAeC,YAAYR,EAAMS,KAAKC,KAAMP,GAClEsB,EAAgBnB,EAAQhE,OACxByH,EAAgBN,EAAQO,WAAaC,OAAOC,iBAC5CC,EAAe,GAGfC,EAAI,CAAC,EACX,IAAI,IAAI7H,EAAI,EAAGA,EAAImH,EAAkBnH,IAAI,CACrC,MAAM8H,EAAaxD,EAAWtE,GACxB+H,EAAQ,CACVV,SAAUS,EACVE,SAAU,CAAC,GAETtD,EAAS,IAAIe,IACnB,IAAI,IAAItF,EAAI,EAAGA,EAAI+E,EAAe/E,IAAI,CAClC,MAAMgF,EAAMpB,EAAQ5D,GACd6F,QAAc,QAAUb,EAAK2C,GAEnC,QAAqB,IAAV9B,EACP,SAEJ,MAAMiC,EAA4B,kBAAVjC,EAAsBA,EAAQ,GAAKA,OACnB,IAA7B+B,EAAMC,SAASC,KACtBF,EAAMC,SAASC,GAAY,CACvBC,QAAS,GACTjD,MAAO,IAGX8C,EAAMC,SAASC,GAAUhD,OAASuC,IAItCO,EAAMC,SAASC,GAAUC,QAAQpH,KAAKX,GACtC4H,EAAMC,SAASC,GAAUhD,QACzBP,EAAOwB,IAAIF,GACf,CACA4B,EAAa9G,KAAKiG,MAAMjC,KAAKJ,IAC7BmD,EAAEC,GAAcC,CACpB,CACA,MAAMI,EAAeC,EAAqBR,GACpCS,EAAqBF,EAAapI,OAClCuI,EAAS,GACf,IAAI,IAAItI,EAAI,EAAGA,EAAIqI,EAAoBrI,IAAI,CACvC,MAAMuI,EAAcJ,EAAanI,GAC3BwI,EAAoBD,EAAYxI,OAChCgI,EAAQ,CACVrD,OAAQ,GACRwD,QAAS,IAEPA,EAAU,GAChB,IAAI,IAAI/H,EAAI,EAAGA,EAAIqI,EAAmBrI,IAAI,CACtC,MAAM6F,EAAQuC,EAAYpI,GACpBkH,EAAW/C,EAAWnE,GAC5B+H,EAAQpH,KAAK+G,EAAER,GAAUW,SAA0B,kBAAVhC,EAAsBA,EAAQ,GAAKA,GAAOkC,SACnFH,EAAMrD,OAAO5D,KAAKkF,EACtB,CAEA+B,EAAMG,SAAU,QAAUA,GAASlH,MAAK,CAACC,EAAGC,IAAID,EAAIC,IAEvB,IAAzB6G,EAAMG,QAAQnI,QAGlBuI,EAAOxH,KAAKiH,EAChB,CACA,MAAMU,EAAeH,EAAOvI,OACtB8G,EAAME,MAAMjC,KAAK,CACnB/E,OAAQ0I,IAEZ,IAAI,IAAIzI,EAAI,EAAGA,EAAIyI,EAAczI,IAAI,CACjC,MAAM+H,EAAQO,EAAOtI,GACf0I,EAASxB,EAAQwB,QAAUjC,EAC3BtC,EAAO4D,EAAMG,QAAQrE,KAAKU,IACrB,CACHT,GAAIF,EAAOW,GACXlE,MAAOU,EAAQwD,GAAO,GACtBoE,SAAU5E,EAAQQ,OAGpBqE,EAAOF,EAAOhC,QAAQmC,KAAK,KAAMd,EAAMrD,QACvCoE,EAAeJ,EAAO5B,gBAAgBiB,EAAMG,QAAQnI,QACpDgJ,EAAmB5E,EAAKuE,OAAOE,EAAME,GAC3CjC,EAAI7G,GAAK,CACL0E,OAAQqD,EAAMrD,OACd6B,OAAQwC,EAEhB,CACA,OAAOlC,CACX,CACA,SAASuB,EAAqBY,EAAMzE,EAAQ,GACxC,GAAIA,EAAQ,IAAMyE,EAAKjJ,OAAQ,OAAOiJ,EAAKzE,GAAOV,KAAKoF,GAAO,CACtDA,KAER,MAAMC,EAAOF,EAAKzE,GACZ4E,EAAIf,EAAqBY,EAAMzE,EAAQ,GACvC4D,EAAe,GACrB,IAAK,MAAMnC,KAASkD,EAChB,IAAK,MAAMX,KAAeY,EAAE,CACxB,MAAM5C,EAAS,CACXP,IAEJ,QAAcO,EAAQgC,GACtBJ,EAAarH,KAAKyF,EACtB,CAEJ,OAAO4B,CACX,C,gFC1IO,MAAMiB,EAAoB,CAC7B,YACA,QACA,iBACA,UAESC,EAAsB,CAC/B,iBACA,qBACA,wBACA,qBAGG9F,eAAe+F,EAAcC,EAAO9F,EAAOK,EAAIqB,GAClD,MAAMqE,EAAcD,EAAMxJ,OAC1B,IAAI,IAAIC,EAAI,EAAGA,EAAIwJ,EAAaxJ,UACtBuJ,EAAMvJ,GAAGyD,EAAOK,EAAIqB,EAElC,CACO5B,eAAekG,EAAgBF,EAAO9F,EAAOiG,GAChD,MAAMF,EAAcD,EAAMxJ,OAC1B,IAAI,IAAIC,EAAI,EAAGA,EAAIwJ,EAAaxJ,UACtBuJ,EAAMvJ,GAAGyD,EAAOiG,EAE9B,CACOnG,eAAeoG,EAAeJ,EAAOK,EAAIC,EAAQC,EAAU/I,GAC9D,MAAMyI,EAAcD,EAAMxJ,OAC1B,IAAI,IAAIC,EAAI,EAAGA,EAAIwJ,EAAaxJ,UACtBuJ,EAAMvJ,GAAG4J,EAAIC,EAAQC,EAAU/I,EAE7C,CACOwC,eAAewG,EAAgBR,EAAOK,EAAIC,EAAQC,GACrD,MAAMN,EAAcD,EAAMxJ,OAC1B,IAAI,IAAIC,EAAI,EAAGA,EAAIwJ,EAAaxJ,UACtBuJ,EAAMvJ,GAAG4J,EAAIC,EAAQC,EAEnC,C,iBCpCO,SAASE,IACZ,MAAO,CACHC,eAAgB,IAAIrK,IACpBsK,eAAgB,GAChBC,OACAC,OAER,CACO,SAASD,EAAKE,GACjB,MAAO,CACHH,eAAgBG,EAAMH,eAE9B,CACO,SAASE,EAAK3G,EAAO6G,GACxB,MAAM,eAAEJ,GAAoBI,EAC5B7G,EAAM8D,wBAAwB0C,eAAeM,QAC7C9G,EAAM8D,wBAAwB2C,eAAiB,GAC/C,IAAI,IAAIlK,EAAI,EAAGA,EAAIkK,EAAenK,OAAQC,IACtCyD,EAAM8D,wBAAwB0C,eAAevJ,IAAIwJ,EAAelK,GAAIA,EAAI,GACxEyD,EAAM8D,wBAAwB2C,eAAepJ,KAAKoJ,EAAelK,GAEzE,CACO,SAASwK,EAAsBH,EAAOvG,GACzC,GAAkB,iBAAPA,EAAiB,CACxB,MAAM2G,EAAaJ,EAAMJ,eAAezJ,IAAIsD,GAC5C,GAAI2G,EACA,OAAOA,EAEX,MAAMC,EAAYL,EAAMJ,eAAeU,KAAO,EAG9C,OAFAN,EAAMJ,eAAevJ,IAAIoD,EAAI4G,GAC7BL,EAAMH,eAAepJ,KAAKgD,GACnB4G,CACX,CACA,OAAI5G,EAAKuG,EAAMH,eAAenK,OACnByK,EAAsBH,EAAOvG,EAAGqC,YAEpCrC,CACX,CACO,SAAS8G,EAA4BP,EAAOI,GAC/C,GAAIJ,EAAMH,eAAenK,OAAS0K,EAC9B,MAAM,IAAII,MAAM,sBAAsBJ,KAE1C,OAAOJ,EAAMH,eAAeO,EAAa,EAC7C,C,+EC3CO,MA+BMK,EAAY,CACrBC,MAAO,6BACPC,QAAS,6BACTC,OAAQ,iCACRC,QAAS,6BACTC,UAAW,6BACXC,WAAY,qBACZC,QAAS,wBACTC,QAAS,6BACTC,QAAS,0BACTC,OAAQ,0BACRC,QAAS,oBACTC,OAAQ,sBACRC,UAAW,kCACXC,SAAU,0BACVC,QAAS,0BACTC,QAAS,4BACTC,WAAY,kCACZC,OAAQ,mBACRC,OAAQ,mBACRC,MAAO,0BACPC,OAAQ,mBACRC,SAAU,mBACVC,MAAO,sBACPC,WAAY,gBACZC,UAAW,4BACXC,UAAW,sBACXC,UAAW,sBACXC,MAAO,mBACPC,SAAU,sCAEDC,EAAsB3J,OAAOoB,KA9DlB,CACpB2H,OAAQ,KACRI,SAAU,KACVK,UAAW,KACXf,OAAQ,KACRX,MAAO,KACPC,QAAS,KACTS,QAAS,KACTR,OAAQ,KACRO,OAAQ,KACRa,MAAO,KACPV,UAAW,KACXQ,OAAQ,KACRG,WAAY,KACZJ,MAAO,KACPhB,QAAS,KACTa,WAAY,KACZE,OAAQ,KACRd,UAAW,KACXC,WAAY,KACZQ,SAAU,KACVP,QAAS,KACTQ,QAAS,KACTW,UAAW,KACXlB,QAAS,KACTC,QAAS,KACTmB,MAAO,KACPZ,QAAS,KACTS,UAAW,KACXI,SAAU,M,0DC3Bd,MACME,EAAS,CACXC,kCAAmC,2EACnCC,uBAAwB,iEAHP,KAAoBzF,KAAK,WAI1C0F,8BAA+B,8CAC/BC,gBAAiB,mRACjBC,4CAA6C,qDAC7CC,sBAAuB,8BACvBC,2BAA4B,yCAC5BC,8CAA+C,kEAC/CC,oBAAqB,mGACrBC,2BAA4B,0DAC5BC,wBAAyB,0CACzBC,wBAAyB,2CACzBC,0BAA2B,oCAC3BC,0BAA2B,0DAC3BC,cAAe,uHACfC,oBAAqB,6DACrBC,yBAA0B,+DAC1BC,0BAA2B,yEAC3BC,yBAA0B,4EAC1BC,qBAAsB,8DACtBC,gCAAiC,2DACjCC,cAAe,oGACfC,0BAA2B,iCAC3BC,0BAA2B,sEAC3BC,wBAAyB,gCACzBC,oBAAqB,iEACrBC,qBAAsB,kEACtBC,qBAAsB,0PACtBC,2BAA4B,4EAC5BC,oBAAqB,wCACrBC,wBAAyB,2EACzBC,oBAAqB,6EACrBC,gCAAiC,kJACjCC,aAAc,8FACdC,qBAAsB,8GACtBC,eAAgB,gGAEb,SAASC,EAAYC,KAASC,GACjC,MAAMC,EAAQ,IAAIxE,OAAM,QAAQgC,EAAOsC,IAAS,iCAAiCA,OAAWC,IAK5F,OAJAC,EAAMF,KAAOA,EACT,sBAAuBtE,MAAMyE,WAC7BzE,MAAM0E,kBAAkBF,GAErBA,CACX,C,iJCvCO9L,eAAeiM,EAAa/L,EAAOoG,EAAQC,EAAW,WACzD,MAAM2F,QAAkB,UACpBhM,EAAMiM,oBACA,QAAgBjM,EAAMiM,aAAcjM,EAAOoG,EAAQC,GAE7D,MAAM,OAAEvH,GAAYsH,EACpB,GAAItH,MAAa,UAAWA,MAAa,aAAcA,IACnD,MAAM,OAAY,uBAAwBU,OAAOoB,KAAK9B,GAAQ+E,KAAK,OAEvE,MAAM,MAAEvB,EAAO,GAAG,OAAED,EAAQ,EAAE,eAAE6J,GAAgB,GAAW9F,EACrD+F,EAAcnM,EAAMS,KAAKK,MAAMsL,cAActN,EAAO8E,UACpDyI,EAAaF,EAAYjF,KACzB9H,EAAU+M,EAAY/M,QACtBkN,EAAwBlG,EAAOlG,QAAUV,OAAOoB,KAAKwF,EAAOlG,QAAQ5D,OAAS,EAC7EiQ,EAAa/M,OAAOoB,KAAKwF,EAAOoG,OAAS,CAAC,GAAGlQ,OAAS,GACtD,MAAEwE,EAAQJ,KAAM+L,GAAezM,EAAMS,KAC3C,IAAK3B,aAAuC,EAASA,EAAOyD,MAAMjG,UAAY+P,EAE1E,MAAM,OAAY,uBAAwBvN,aAAuC,EAASA,EAAO8E,SAAUyI,EAAYvN,aAAuC,EAASA,EAAOyD,MAAMjG,QAElLwC,aAAkB4N,eACpB5N,EAAOyD,MAAQ,IAAImK,aAAa5N,EAAOyD,QAE3C,IAAIjF,GAAU,OAAmBwB,EAAOyD,MAAOnD,EAASiN,EAAYjG,EAAO1G,YAAYU,KAAI,EAAEC,EAAIzD,KAAS,EAClG,QAAsBoD,EAAM8D,wBAAyBzD,GACrDzD,KAEJ+P,EAAqB3M,EAAM4M,OAA2B,mBAC1D,IAAKD,EAAoB,CACrB,MAAME,QAAoC7M,EAAMc,MAAMC,iCAAiCD,GACvF6L,QAA2B3M,EAAMc,MAAMgM,wBAAwBhM,GAC/D6L,EAAqBA,EAAmBI,QAAQC,GAAOH,EAA4BG,GAAMC,WAAW,YACpGjN,EAAM4M,OAA2B,mBAAID,CACzC,CACA,MACMO,QAAgB,IAAAC,qBAAoBnN,EAAMoN,UAAWpN,EAAMc,MAAOd,EAAMO,eAAgB8F,EAAUD,EAAQuG,EADjG,SACmI3M,EAAMO,eAAeiB,MAAMiL,GAAYT,GACzL,IAAIqB,EAAkB,GAClBd,IACAc,QAAwBrN,EAAMc,MAAMwM,oBAAoBJ,EAASpM,EAAOsF,EAAOoG,OAC/ElP,GAAU,OAAqB+P,EAAiB/P,IAEpD,IAAIiQ,EAAgB,GAChBjB,IAGAiB,QADqB,OAAUvN,EAAO1C,EAAS8I,EAAOlG,SAG1D,MAAMQ,EAAO4C,MAAMjC,KAAK,CACpB/E,OAAQgG,IAEZ,IAAI,IAAI/F,EAAI,EAAGA,EAAI+F,EAAO/F,IAAI,CAC1B,MAAMuG,EAASxF,EAAQf,EAAI8F,GAC3B,IAAKS,EACD,MAEJ,MAAMpB,EAAM1B,EAAMS,KAAKC,KAAKA,KAAKoC,EAAO,IACxC,GAAIpB,EAAK,CACAwK,IACDxK,EAAI5C,EAAO8E,UAAY,MAE3B,MAAM4J,EAAS,CACXnN,IAAI,QAA4BL,EAAM8D,wBAAyBhB,EAAO,IACtElG,MAAOkG,EAAO,GACdoC,SAAUxD,GAEdhB,EAAKnE,GAAKiR,CACd,CACJ,CACA,IAAI3I,EAAS,GACTuB,EAAO3C,UACPoB,QAAe,OAAU7E,EAAO1C,EAAS8I,EAAO3C,UAEhDzD,EAAMyN,mBACA,QAAezN,EAAMyN,YAAazN,EAAOoG,EAAQC,EAAU/I,GAErE,MACMoQ,QADgB,UACQ1B,EAC9B,MAAO,CACHxK,MAAOlE,EAAQhB,OACfqR,KAAMjN,EAAKqM,OAAOa,SAClBC,QAAS,CACLhH,IAAK5C,OAAOyJ,GACZI,gBAAiB,QAAkBJ,OAEpCH,EAAgB,CACfrN,OAAQqN,GACR,CAAC,KACF1I,EAAS,CACRA,UACA,CAAC,EAEb,C,wLCpGO,MAAMkJ,EAAuB,WACvBC,EAAqB,SACrBC,EAAqB,S,yECiFlCnO,eAAeoO,EAAqBlO,EAAOoG,EAAQC,GAC/C,MAAM2F,QAAkB,UACxB5F,EAAO+H,UAAY3O,OAAO4O,OAAOhI,EAAO+H,WAAa,CAAC,EAAGE,GACzD,MAAM,KAAEC,EAAK,WAAEzN,EAAW,UAAE7E,EAAW,GAAOoK,GACxC,MAAEtF,EAAM,KAAEJ,GAAUV,EAAMS,KAC1B8N,QAAevO,EAAMoN,UAAUoB,SAASF,GAAQ,GAAIjI,GAE1D,IAAIsG,EAAqB3M,EAAM4M,OAA2B,mBAC1D,IAAKD,EAAoB,CACrB,MAAME,QAAoC7M,EAAMc,MAAMC,iCAAiCD,GACvF6L,QAA2B3M,EAAMc,MAAMgM,wBAAwBhM,GAC/D6L,EAAqBA,EAAmBI,QAAQC,GAAOH,EAA4BG,GAAMC,WAAW,YACpGjN,EAAM4M,OAA2B,mBAAID,CACzC,CACA,GAAI9L,GAA6B,MAAfA,EAAoB,CAClC,IAAK,MAAMmM,KAAQnM,EACf,IAAK8L,EAAmB/K,SAASoL,GAC7B,MAAM,OAAY,gBAAiBA,EAAML,EAAmB9I,KAAK,OAGzE8I,EAAqBA,EAAmBI,QAAQC,GAAOnM,EAAWe,SAASoL,IAC/E,CAEA,MAAME,QAAgBC,EAAoBnN,EAAMoN,UAAWpN,EAAMc,MAAOd,EAAMO,eAAgB8F,EAAUD,EAAQuG,EAAoB4B,QAAcvO,EAAMO,eAAeiB,MAAMd,GAAOsL,GAC9KyC,EAAeF,EAAOjS,OAC5B,GAAImS,GAAgB5N,GAAcA,EAAWvE,OAAS,EAAG,CAErD,MAAMoS,EAAgB/B,EAAmBrQ,OACzC,IAAI,IAAIC,EAAI,EAAGA,EAAImS,EAAenS,IAAI,CAClC,IAAIoS,EACJ,MAAM3B,EAAOL,EAAmBpQ,GAChC,GAAqB,IAAjBkS,EACA,IAAI,IAAI/R,EAAI,EAAGA,EAAI+R,EAAc/R,IAAI,CACjC,MAAM4R,EAAOC,EAAO7R,GAEdkS,QAAkB5O,EAAMc,MAAM+N,OAAO3B,EAASpM,EAAOkM,EAAMsB,IACjE,QAAcpB,EAAQ4B,SAAS9B,GAAMsB,GAAOM,EAChD,KACG,CACH1B,EAAQ4B,SAAS9B,GAAM,IAAM,GAC7B,MAAM4B,QAAkB5O,EAAMc,MAAM+N,OAAO3B,EAASpM,EAAOkM,EAAM,KACjE,QAAcE,EAAQ4B,SAAS9B,GAAM,IAAK4B,EAC9C,CACA,MAAMG,EAAS7B,EAAQ4B,SAAS9B,GAC1BgC,EAAOxP,OAAOyB,OAAO8N,GAC3B7B,EAAQ+B,iBAAiBjC,IAAQ,OAAsBgC,GAAO5I,SAAmF,QAAlCuI,EAAgBvI,EAAOrK,aAAqC,IAAlB4S,OAApD,EAAwFA,EAAc3B,KAAU,EAAGhR,EAAWyS,GACnO,MAAMS,EAAahC,EAAQ+B,iBAAiBjC,GACtCmC,EAAmBD,EAAW5S,OACpC,IAAI,IAAIC,EAAI,EAAGA,EAAI4S,EAAkB5S,IAAI,CACrC,MAAO8D,EAAIzD,GAASsS,EAAW3S,GACzB6S,EAAYlC,EAAQmC,cAAchP,GAEpC6M,EAAQmC,cAAchP,GADtB+O,EAC4BA,EAAYxS,EAAQ,GAEpBA,CAEpC,CACJ,CACJ,MAA6B,IAAlB2R,EAAOjS,QAAgBgS,EAI9BpB,EAAQmC,cAAgB,CAAC,EAEzBnC,EAAQmC,cAAgB7P,OAAO+B,YAAY/B,OAAOoB,WAAWZ,EAAMO,eAAe+O,OAAOtP,EAAMS,KAAKC,OAAON,KAAK1B,GAAI,CAC5GA,EACA,MAOZ,OAAO6Q,EAJW/P,OAAOpC,QAAQ8P,EAAQmC,eAAejP,KAAI,EAAEC,EAAIzD,KAAS,EAClEyD,EACDzD,KACDW,MAAK,CAACC,EAAGC,IAAIA,EAAE,GAAKD,EAAE,KAEjC,CACOsC,eAAe0P,EAAmBxP,EAAOoG,GAC5C,MAAMtH,EAASsH,EAAOtH,OAEhBqN,EAAcnM,EAAMS,KAAKK,MAAMsL,cAActN,aAAuC,EAASA,EAAO8E,UACpGyI,EAAaF,EAAYjF,KACzB9H,EAAU+M,EAAY/M,QAC5B,GAAIN,KAAYA,EAAOyD,QAAUzD,EAAO8E,UACpC,MAAM,OAAY,uBAAwBpE,OAAOoB,KAAK9B,GAAQ+E,KAAK,OAEvE,GAAI/E,EAAOyD,MAAMjG,SAAW+P,EACxB,MAAM,OAAY,uBAAwBvN,EAAO8E,SAAUyI,EAAYvN,EAAOyD,MAAMjG,QASxF,OAPMwC,aAAkB4N,eACpB5N,EAAOyD,MAAQ,IAAImK,aAAa5N,EAAOyD,QAMpCgN,GAJW,OAAmBzQ,EAAOyD,MAAOnD,EAASiN,EAAYjG,EAAO1G,YAAYU,KAAI,EAAEC,EAAIzD,KAAS,EACtG,QAAsBoD,EAAM8D,wBAAyBzD,GACrDzD,KAGZ,CACA,SAAS2S,EAAyBjS,GAC9B,MAAMmS,EAAWxR,KAAKyR,OAAOpS,EAAQ8C,KAAI,EAAE,CAAExD,KAASA,KACtD,OAAOU,EAAQ8C,KAAI,EAAEC,EAAIzD,KAAS,CAC1ByD,EACAzD,EAAQ6S,IAEpB,CACA,SAASE,EAAe/S,EAAO6S,GAC3B,OAAO7S,EAAQ6S,CACnB,CACA,SAASG,EAAYC,EAAWC,EAAaC,EAAYC,GACrD,OAAOH,EAAYE,EAAaD,EAAcE,CAClD,CCxLO,MAAM3B,EAAoB,CAC7B3P,EAAG,IACHjB,EAAG,IACHkB,EAAG,IAEAmB,eAAeqN,EAAoBC,EAAWtM,EAAOP,EAAgB8F,EAAUD,EAAQvF,EAAY0N,EAAQjQ,EAAW0N,GAoBzH,MAAM8C,EAAW,CAAC,EAUZG,EAAmB,CAAC,EAC1B,IAAK,MAAMjC,KAAQnM,EAAW,CAC1B,MAAMoP,EAAY,CAAC,EACnB,IAAK,MAAMtT,KAAS4R,EAChB0B,EAAUtT,GAAS,GAEvBmS,EAAS9B,GAAQiD,EACjBhB,EAAiBjC,GAAQ,EAC7B,CACA,MAAO,CACHhB,YACAoB,YACAtM,QACAP,iBACA8F,WACAD,SACA9H,YACA+Q,cAAe,CAAC,EAChBP,WACAG,mBAER,CACOnP,eAAe+O,EAAO7O,EAAOoG,EAAQC,GACxC,MAAM6J,EAAO9J,EAAO8J,MAAQnC,EAC5B,GAAImC,IAASnC,EACT,OC1DDjO,eAA8BE,EAAOoG,EAAQC,GAChD,MAAM2F,QAAkB,UACpBhM,EAAMiM,oBACA,QAAgBjM,EAAMiM,aAAcjM,EAAOoG,EAAQC,GAE7DD,EAAO+H,UAAY3O,OAAO4O,OAAOhI,EAAO+H,WAAa,CAAC,EAAGE,GACzD,MAAM8B,EAAmB3Q,OAAOoB,KAAKZ,EAAMS,KAAKK,MAAMsL,eAChDE,EAAwBlG,EAAOlG,QAAUV,OAAOoB,KAAKwF,EAAOlG,QAAQ5D,OAAS,GAC7E,MAAEgG,EAAO,GAAG,OAAED,EAAQ,EAAE,KAAEiM,EAAK,WAAEzN,EAAW,UAAE7E,EAAW,EAAE,WAAEoU,EAAW,eAAElE,GAAgB,GAAW9F,EACrGiK,GAAmC,IAArBjK,EAAOkK,WACrB,MAAExP,EAAM,KAAEJ,GAAUV,EAAMS,KAC1B8N,QAAevO,EAAMoN,UAAUoB,SAASF,GAAQ,GAAIjI,GAE1D,IAAIsG,EAAqB3M,EAAM4M,OAA2B,mBAC1D,IAAKD,EAAoB,CACrB,MAAME,QAAoC7M,EAAMc,MAAMC,iCAAiCD,GACvF6L,QAA2B3M,EAAMc,MAAMgM,wBAAwBhM,GAC/D6L,EAAqBA,EAAmBI,QAAQC,GAAOH,EAA4BG,GAAMC,WAAW,YACpGjN,EAAM4M,OAA2B,mBAAID,CACzC,CACA,GAAI9L,GAA6B,MAAfA,EAAoB,CAClC,IAAK,MAAMmM,KAAQnM,EACf,IAAK8L,EAAmB/K,SAASoL,GAC7B,MAAM,OAAY,gBAAiBA,EAAML,EAAmB9I,KAAK,OAGzE8I,EAAqBA,EAAmBI,QAAQC,GAAOnM,EAAWe,SAASoL,IAC/E,CAEA,MAAME,QAAgBC,EAAoBnN,EAAMoN,UAAWpN,EAAMc,MAAOd,EAAMO,eAAgB8F,EAAUD,EAAQuG,EAAoB4B,QAAcvO,EAAMO,eAAeiB,MAAMd,GAAOsL,GAE9KO,EAAa/M,OAAOoB,KAAKwF,EAAOoG,OAAS,CAAC,GAAGlQ,OAAS,EAC5D,IAAI+Q,EAAkB,GAClBd,IACAc,QAAwBrN,EAAMc,MAAMwM,oBAAoBJ,EAASpM,EAAOsF,EAAOoG,QAEnF,MAAMiC,EAAeF,EAAOjS,OAC5B,GAAImS,GAAgB5N,GAAcA,EAAWvE,OAAS,EAAG,CAErD,MAAMoS,EAAgB/B,EAAmBrQ,OACzC,IAAI,IAAIC,EAAI,EAAGA,EAAImS,EAAenS,IAAI,CAClC,IAAIoS,EACJ,MAAM3B,EAAOL,EAAmBpQ,GAChC,GAAqB,IAAjBkS,EACA,IAAI,IAAI/R,EAAI,EAAGA,EAAI+R,EAAc/R,IAAI,CACjC,MAAM4R,EAAOC,EAAO7R,GAEdkS,QAAkB5O,EAAMc,MAAM+N,OAAO3B,EAASpM,EAAOkM,EAAMsB,IACjE,QAAcpB,EAAQ4B,SAAS9B,GAAMsB,GAAOM,EAChD,KACG,CACH1B,EAAQ4B,SAAS9B,GAAM,IAAM,GAC7B,MAAM4B,QAAkB5O,EAAMc,MAAM+N,OAAO3B,EAASpM,EAAOkM,EAAM,KACjE,QAAcE,EAAQ4B,SAAS9B,GAAM,IAAK4B,EAC9C,CACA,MAAMG,EAAS7B,EAAQ4B,SAAS9B,GAC1BgC,EAAOxP,OAAOyB,OAAO8N,GAC3B7B,EAAQ+B,iBAAiBjC,IAAQ,OAAsBgC,GAAO5I,SAAmF,QAAlCuI,EAAgBvI,EAAOrK,aAAqC,IAAlB4S,OAApD,EAAwFA,EAAc3B,KAAU,EAAGhR,EAAWyS,GACnO,MAAMS,EAAahC,EAAQ+B,iBAAiBjC,GACtCmC,EAAmBD,EAAW5S,OACpC,IAAI,IAAIC,EAAI,EAAGA,EAAI4S,EAAkB5S,IAAI,CACrC,MAAO8D,EAAIzD,GAASsS,EAAW3S,GACzB6S,EAAYlC,EAAQmC,cAAchP,GAEpC6M,EAAQmC,cAAchP,GADtB+O,EAC4BA,EAAYxS,EAAQ,GAEpBA,CAEpC,CACJ,CACJ,MAA6B,IAAlB2R,EAAOjS,QAAgBgS,EAI9BpB,EAAQmC,cAAgB,CAAC,EAEzBnC,EAAQmC,cAAgB7P,OAAO+B,YAAY/B,OAAOoB,WAAWZ,EAAMO,eAAe+O,OAAOtP,EAAMS,KAAKC,OAAON,KAAK1B,GAAI,CAC5GA,EACA,MAIZ,IA+BIpB,EA/BAiT,EAAkB/Q,OAAOpC,QAAQ8P,EAAQmC,eAAejP,KAAI,EAAEC,EAAIzD,KAAS,EACtEyD,EACDzD,KAMR,GAHI2P,IACAgE,GAAkB,OAAqBlD,EAAiBkD,IAExDnK,EAAOoK,OACP,GAA6B,mBAAlBpK,EAAOoK,OAAuB,CACrC,MAAMC,EAAMF,EAAgBnQ,KAAI,EAAEC,KAAMA,IAElCqQ,SADa1Q,EAAMO,eAAeC,YAAYR,EAAMS,KAAKC,KAAM+P,IACrCrQ,KAAI,CAACzB,EAAGpC,IAAI,CACpCgU,EAAgBhU,GAAG,GACnBgU,EAAgBhU,GAAG,GACnBoC,KAER+R,EAAmBnT,KAAK6I,EAAOoK,QAC/BD,EAAkBG,EAAmBtQ,KAAI,EAAEC,EAAIzD,KAAS,CAChDyD,EACAzD,IAEZ,MACI2T,QAAwBvQ,EAAM2Q,OAAOH,OAAOxQ,EAAMS,KAAKmQ,QAASL,EAAiBnK,EAAOoK,QAAQK,MAAMvT,GAAUA,EAAQ8C,KAAI,EAAEC,EAAIzD,KAAS,EAC/H,QAAsBoD,EAAM8D,wBAAyBzD,GACrDzD,YAIhB2T,EAAkBA,EAAgBhT,KAAK,OAGtC8S,GAAeD,EAChB9S,QAAgBwT,EAA2B9Q,EAAOuQ,EAAiBlO,EAAQC,EAAO8N,GAC1EC,IACR/S,QAAgByT,EAAe/Q,EAAOuQ,EAAiBlO,EAAQC,IAEnE,MAAM0O,EAAe,CACjBnD,QAAS,CACLC,UAAW,GACXjH,IAAK,GAGT8G,KAAM,GACNnM,MAAO+O,EAAgBjU,QAS3B,QAPuB,IAAZgB,IACP0T,EAAarD,KAAOrQ,EAAQyP,OAAOa,SAE9B1B,IACD,QAAsB8E,EAAcb,IAGxC7D,EAAuB,CAEvB,MAAMpM,QAAe,OAAUF,EAAOuQ,EAAiBnK,EAAOlG,QAC9D8Q,EAAa9Q,OAASA,CAC1B,CASA,OARIkG,EAAO3C,UACPuN,EAAanM,aAAe,OAAU7E,EAAOuQ,EAAiBnK,EAAO3C,UAErEzD,EAAMyN,mBACA,QAAezN,EAAMyN,YAAazN,EAAOoG,EAAQC,EAAU2K,GAGrEA,EAAanD,cAAgB7N,EAAMiR,wBAAwB,UAAuB/D,EAAQlB,WACnFgF,CACX,CD3FeE,CAAelR,EAAOoG,EAAQC,GAEzC,GAAI6J,IAASjC,EACT,OAAO,IAAAlC,cAAa/L,EAAOoG,GAE/B,GAAI8J,IAASlC,EACT,OD9DDlO,eAA4BE,EAAOoG,EAAQC,GAC9C,MAAM2F,QAAkB,UACpBhM,EAAMiM,oBACA,QAAgBjM,EAAMiM,aAAcjM,EAAOoG,EAAQC,GAE7D,MAAM,OAAEhE,EAAQ,EAAE,MAAEC,EAAO,GAAG,eAAE4J,GAAgB,GAAW9F,EACrDkG,EAAwBlG,EAAOlG,QAAUV,OAAOoB,KAAKwF,EAAOlG,QAAQ5D,OAAS,GAC5E6U,EAAaC,SAAmBC,QAAQC,IAAI,CAC/CpD,EAAqBlO,EAAOoG,EAAQC,GACpCmJ,EAAmBxP,EAAOoG,MAExB,MAAEtF,EAAM,KAAEJ,GAAUV,EAAMS,KAChC,IAAI8Q,EAyKR,SAA6BC,EAAaC,EAAeC,GACrD,MAAMC,EAAe1T,KAAKyR,OAAO8B,EAAYpR,KAAI,EAAE,CAAExD,KAASA,KACxDgV,EAAiB3T,KAAKyR,OAAO+B,EAAcrR,KAAI,EAAE,CAAExD,KAASA,MAC5D,WAAEmT,EAAW,aAAEC,GAiCd,CACHD,WAAY,GACZC,aAAc,IAlCZ6B,EAAgB,IAAI1V,IACpB2V,EAAoBN,EAAYlV,OACtC,IAAI,IAAIC,EAAI,EAAGA,EAAIuV,EAAmBvV,IAAI,CACtC,MAEMwV,EAAmBnC,EAFDD,EAAe6B,EAAYjV,GAAG,GAAIoV,GAEJ,EAAG5B,EAAYC,GACrE6B,EAAc5U,IAAIuU,EAAYjV,GAAG,GAAIwV,EAEzC,CACA,MAAMC,EAAsBP,EAAcnV,OAC1C,IAAI,IAAIC,EAAI,EAAGA,EAAIyV,EAAqBzV,IAAI,CACxC,MAAM0V,EAAkBtC,EAAe8B,EAAclV,GAAG,GAAIqV,GAE5D,GAAIC,EAAcrP,IAAIiP,EAAclV,GAAG,IAAK,CACxC,IAAI2V,EAAcL,EAAc9U,IAAI0U,EAAclV,GAAG,IAErDsV,EAAc5U,IAAIwU,EAAclV,GAAG,GAAI2V,GAAetC,EAAY,EAAGqC,EAAiBlC,EAAYC,GAEtG,MACI6B,EAAc5U,IAAIwU,EAAclV,GAAG,GAAIqT,EAAY,EAAGqC,EAAiBlC,EAAYC,GAG3F,CACA,MAAO,IACA6B,GACLtU,MAAK,CAACC,EAAGC,IAAIA,EAAE,GAAKD,EAAE,IAC5B,CAvM4B2U,CAAoBhB,EAAaC,EAAWhL,EAAOkI,MAE3E,MAAMC,QAAevO,EAAMoN,UAAUoB,SAASpI,EAAOkI,MAAQ,GAAIjI,GACjE,IAAIsG,EAAqB3M,EAAM4M,OAA2B,mBAC1D,IAAKD,EAAoB,CACrB,MAAME,QAAoC7M,EAAMc,MAAMC,iCAAiCD,GACvF6L,QAA2B3M,EAAMc,MAAMgM,wBAAwBhM,GAC/D6L,EAAqBA,EAAmBI,QAAQC,GAAOH,EAA4BG,GAAMC,WAAW,YACpGjN,EAAM4M,OAA2B,mBAAID,CACzC,CACA,GAAIvG,EAAOvF,YAAoC,MAAtBuF,EAAOvF,WAAoB,CAChD,IAAK,MAAMmM,KAAQ5G,EAAOvF,WACtB,IAAK8L,EAAmB/K,SAASoL,GAC7B,MAAM,OAAY,gBAAiBA,EAAML,EAAmB9I,KAAK,OAGzE8I,EAAqBA,EAAmBI,QAAQC,GAAO5G,EAAOvF,WAAWe,SAASoL,IACtF,CAEA,MAAME,QAAgBC,EAAoBnN,EAAMoN,UAAWpN,EAAMc,MAAOd,EAAMO,eAAgB8F,EAAUD,EAAQuG,EAAoB4B,QAAcvO,EAAMO,eAAeiB,MAAMd,GAAOsL,GAEpL,IAKIuB,EAKA1I,EAVAwI,EAAkB,GADH7N,OAAOoB,KAAKwF,EAAOoG,OAAS,CAAC,GAAGlQ,OAAS,IAGxD+Q,QAAwBrN,EAAMc,MAAMwM,oBAAoBJ,EAASpM,EAAOsF,EAAOoG,OAC/E+E,GAAoB,OAAqBlE,EAAiBkE,GAAmBxT,MAAMsE,EAAQA,EAASC,IAGpGgK,IAEAiB,QADqB,OAAUvN,EAAOuR,EAAmBnL,EAAOlG,SAIhEkG,EAAO3C,UACPoB,QAAe,OAAU7E,EAAOuR,EAAmBnL,EAAO3C,UAE9D,MAAMnG,SAAiByT,EAAe/Q,EAAOuR,EAAmBlP,EAAQC,IAAQyK,OAAOa,SACnF5N,EAAMyN,mBACA,QAAezN,EAAMyN,YAAazN,EAAOoG,EAAQC,EAAU/I,GAErE,MAAM8U,QAAgB,UAChBC,EAAmB,CACrB7Q,MAAO+P,EAAkBjV,OACzBuR,QAAS,CACLhH,IAAK5C,OAAOmO,EAAUpG,GACtB8B,gBAAiB,QAAkBsE,EAAUpG,IAEjD2B,KAAMrQ,KACHiQ,EAAgB,CACfrN,OAAQqN,GACR,CAAC,KACF1I,EAAS,CACRA,UACA,CAAC,GAET,IAAKqH,EAAgB,CACjB,MAAMiE,EAAmB3Q,OAAOoB,KAAKZ,EAAMS,KAAKK,MAAMsL,gBACtD,QAAsBiG,EAAkBlC,EAC5C,CACA,OAAOkC,CACX,CCTeC,CAAatS,EAAOoG,GAE/B,MAAM,OAAY,sBAAuB8J,EAC7C,CACOpQ,eAAegR,EAA2B9Q,EAAOuQ,EAAiBlO,EAAQC,EAAO8N,GACpF,MAAM1P,EAAOV,EAAMS,KAAKC,KAElBO,EAAS,IAAI9E,IAGbmB,EAAU,GACViV,EAAY,IAAIvQ,IAChBwQ,EAAwBjC,EAAgBjU,OAC9C,IAAIkF,EAAQ,EACZ,IAAI,IAAIjF,EAAI,EAAGA,EAAIiW,EAAuBjW,IAAI,CAC1C,MAAMkW,EAAalC,EAAgBhU,GAEnC,QAA0B,IAAfkW,EACP,SAEJ,MAAOpS,EAAIzD,GAAS6V,EACpB,GAAIF,EAAU/P,IAAInC,GACd,SAEJ,MAAMqB,QAAY1B,EAAMO,eAAexD,IAAI2D,EAAML,GAC3CkC,QAAc,QAAUb,EAAK0O,GACnC,QAAqB,IAAV7N,IAAyBtB,EAAOuB,IAAID,KAG/CtB,EAAOhE,IAAIsF,GAAO,GAClBf,MAEIA,GAASa,KAGb/E,EAAQD,KAAK,CACTgD,IAAI,QAA4BL,EAAM8D,wBAAyBzD,GAC/DzD,QACAsI,SAAUxD,IAEd6Q,EAAU9P,IAAIpC,GAEVmB,GAASa,EAASC,IAClB,KAER,CACA,OAAOhF,CACX,CACOwC,eAAeiR,EAAe/Q,EAAOuQ,EAAiBlO,EAAQC,GACjE,MAAM5B,EAAOV,EAAMS,KAAKC,KAClBpD,EAAUgG,MAAMjC,KAAK,CACvB/E,OAAQgG,IAENiQ,EAAY,IAAIvQ,IAItB,IAAI,IAAIzF,EAAI8F,EAAQ9F,EAAI+F,EAAQD,EAAQ9F,IAAI,CACxC,MAAMkW,EAAalC,EAAgBhU,GAEnC,QAA0B,IAAfkW,EACP,MAEJ,MAAOpS,EAAIzD,GAAS6V,EACpB,IAAKF,EAAU/P,IAAInC,GAAK,CAGpB,MAAMqS,QAAgB1S,EAAMO,eAAexD,IAAI2D,EAAML,GACrD/C,EAAQf,GAAK,CACT8D,IAAI,QAA4BL,EAAM8D,wBAAyBzD,GAC/DzD,QACAsI,SAAUwN,GAEdH,EAAU9P,IAAIpC,EAClB,CACJ,CACA,OAAO/C,CACX,C,6JErJA,MAAMqV,EAASC,KAAKC,MAAMnQ,WAAW3E,MAAM,GAC3C,IAAI+U,EAAS,EACb,MAAMpU,EAAI,KACJqU,EAAOC,OAAO,KACdC,EAAQD,OAAO,KACfE,EAASF,OAAO,KAMLG,EAAyB,MAS/B,SAASC,EAAc5W,EAAK6W,GACnC,GAAIA,EAAO/W,OAAS6W,EAChB7P,MAAMuI,UAAUxO,KAAKiW,MAAM9W,EAAK6W,QAEhC,IAAI,IAAI9W,EAAI,EAAGA,EAAI8W,EAAO/W,OAAQC,GAAK4W,EACnC7P,MAAMuI,UAAUxO,KAAKiW,MAAM9W,EAAK6W,EAAOtV,MAAMxB,EAAGA,EAAI4W,GAGhE,CACO,SAASI,EAAQC,KAAa7H,GACjC,OAAO6H,EAASC,QAAQ,gEAAgE,YAAYC,GAChG,MAAM7O,EAAS6O,EAAYA,EAAYpX,OAAS,IACxCqX,MAAOC,EAAS,KAAEC,EAAK,SAAEC,GAAcjP,EACzCkP,EAAcD,EAAWnI,EAAK1H,OAAO+P,SAASF,GAAY,GAAKnI,EAAKsI,QACpEN,EAAqB,KAAbC,EAAkB,EAAI3P,OAAO+P,SAASJ,GACpD,OAAOC,GACH,IAAK,IACD,OAAOE,EAAYrR,WAAWwR,SAASP,EAAO,KAClD,IAAK,IACD,CACI,IAAIpR,EAAQwR,EACZ,MAAOI,EAASC,GAAaR,EAASS,MAAM,KAAKjU,KAAKkU,GAAIrQ,OAAOsQ,WAAWD,KAI5E,MAHyB,iBAAdF,GAA0BA,GAAa,IAC9C7R,EAAQA,EAAMiS,QAAQJ,IAEA,iBAAZD,GAAwBA,GAAW,EAAI5R,EAAMG,WAAWwR,SAASP,EAAO,KAAOpR,EAAMG,UACvG,CACJ,IAAK,IACD,OAAOiR,EAAQ,EAAII,EAAYrR,WAAW+R,QAAQd,EAAO,KAAOI,EAAYrR,WAAWwR,SAASP,EAAO,KAC3G,QACI,OAAOI,EAEnB,GACJ,CACOjU,eAAe4U,EAAYC,EAAOC,EAAW,GAChD,GAAc,IAAVD,EACA,MAAO,UAEX,MAAME,EAAKD,EAAW,EAAI,EAAIA,EAYxBrY,EAAI0B,KAAK6W,MAAM7W,KAAKW,IAAI+V,GAAS1W,KAAKW,IAAIF,IAChD,MAAO,GAAG6V,YAAYI,EAAQ1W,KAAK8W,IAAIrW,EAAGnC,IAAIiY,QAAQK,OAZxC,CACV,QACA,KACA,KACA,KACA,KACA,KACA,KACA,KACA,MAGgEtY,IACxE,CAQO,SAASyY,IACZ,OAAOhC,OAAO/U,KAAK6W,MAA0B,IAApBG,YAAYpC,OACzC,CACO/S,eAAeoV,EAAkB3S,GAIpC,MAHqB,iBAAVA,IACPA,EAAQyQ,OAAOzQ,IAEfA,EAAQwQ,EACD,GAAGxQ,MACHA,EAAQ0Q,EACL1Q,EAAQwQ,EAAX,KACAxQ,EAAQ2Q,EACL3Q,EAAQ0Q,EAAX,KAED1Q,EAAQ2Q,EAAX,GACX,CACOpT,eAAeqV,IAClB,MAtBoC,oBAAtBC,mBAAqCC,gBAAgBD,kBAuBxDJ,IApBe,oBAAZM,SAA2BA,QAAQC,SAAoC,SAAzBD,QAAQC,QAAQC,MAyBrD,oBAAZF,cAA8CtY,IAAnBsY,QAAQG,OAFnCH,QAAQG,OAAOC,SAKC,oBAAhBT,YACAD,IAGJhC,OAAO,EAClB,CACOlT,eAAe6V,IAClB,MAAO,GAAGhD,KAAUG,KACxB,CACO,SAAS8C,EAAeC,EAAQjS,GAEnC,YAAsB5G,IAAlBwC,OAAOsW,OACAtW,OAAOqM,UAAUkK,eAAeC,KAAKH,EAAQjS,GAAYiS,EAAOjS,QAAY5G,EAEhFwC,OAAOsW,OAAOD,EAAQjS,GAAYiS,EAAOjS,QAAY5G,CAChE,CAyBO,SAASiZ,EAAwBzY,EAAGC,GACvC,OAAIA,EAAE,KAAOD,EAAE,GACJA,EAAE,GAAKC,EAAE,GAEbA,EAAE,GAAKD,EAAE,EACpB,CAGO,SAAS0Y,EAAUpa,GACtB,GAAsB,IAAlBA,EAAOQ,OACP,MAAO,GACJ,GAAsB,IAAlBR,EAAOQ,OACd,OAAOR,EAAO,GAElB,IAAI,IAAIS,EAAI,EAAGA,EAAIT,EAAOQ,OAAQC,IAC9B,GAAIT,EAAOS,GAAGD,OAASR,EAAO,GAAGQ,OAAQ,CACrC,MAAM6E,EAAMrF,EAAO,GACnBA,EAAO,GAAKA,EAAOS,GACnBT,EAAOS,GAAK4E,CAChB,CAEJ,MAAMlE,EAAM,IAAId,IAChB,IAAK,MAAMga,KAAQra,EAAO,GACtBmB,EAAIA,IAAIkZ,EAAM,GAElB,IAAI,IAAI5Z,EAAI,EAAGA,EAAIT,EAAOQ,OAAQC,IAAI,CAClC,IAAI6Z,EAAQ,EACZ,IAAK,MAAMD,KAAQra,EAAOS,GAAG,CACzB,MAAMiF,EAAQvE,EAAIF,IAAIoZ,GAClB3U,IAAUjF,IACVU,EAAIA,IAAIkZ,EAAM3U,EAAQ,GACtB4U,IAER,CACA,GAAc,IAAVA,EAAa,MAAO,EAC5B,CACA,OAAOta,EAAO,GAAGiR,QAAQsJ,IACrB,MAAM7U,EAAQvE,EAAIF,IAAIsZ,GAEtB,YADcrZ,IAAVwE,GAAqBvE,EAAIA,IAAIoZ,EAAG,GAC7B7U,IAAU1F,EAAOQ,MAAM,GAEtC,CACOwD,eAAewW,EAAsB5U,EAAK6U,GAC7C,MAAM1V,EAAa,CAAC,EACd2V,EAAcD,EAAMja,OAC1B,IAAI,IAAIC,EAAI,EAAGA,EAAIia,EAAaja,IAAI,CAChC,MAAMka,EAAOF,EAAMha,GACbma,EAAaD,EAAKpC,MAAM,KAC9B,IAAIsC,EAAUjV,EACd,MAAMkV,EAAmBF,EAAWpa,OACpC,IAAI,IAAII,EAAI,EAAGA,EAAIka,EAAkBla,IAGjC,GAFAia,EAAUA,EAAQD,EAAWha,IAEN,iBAAZia,EAAsB,CAC7B,GAAgB,OAAZA,GAAoB,QAASA,GAAW,QAASA,GAAkC,iBAAhBA,EAAQE,KAA2C,iBAAhBF,EAAQG,IAAkB,CAChIH,EAAU9V,EAAW4V,GAAQE,EAC7B,KACJ,CAAO,IAAKrT,MAAMyT,QAAQJ,IAAwB,OAAZA,GAAoBja,IAAMka,EAAmB,EAAG,CAClFD,OAAU3Z,EACV,KACJ,CACJ,MAAO,IAAiB,OAAZ2Z,GAAuC,iBAAZA,IAAyBja,EAAIka,EAAmB,EAAG,CAEtFD,OAAU3Z,EACV,KACJ,MAEmB,IAAZ2Z,IACP9V,EAAW4V,GAAQE,EAE3B,CACA,OAAO9V,CACX,CACOf,eAAekX,EAAUC,EAAKR,GAIjC,aAHoBH,EAAsBW,EAAK,CAC3CR,KAESA,EACjB,CAcA,MAAMS,EAAsB,CACxBC,GAAI,IACJC,EAAG,EACHC,GAAI,IACJC,GAAI,MACJC,GAAI,MACJC,GAAI,UAED,SAASC,EAAwBC,EAAUC,GAC9C,MAAMC,EAAQV,EAAoBS,GAClC,QAAc3a,IAAV4a,EACA,MAAM,IAAIxQ,OAAM,OAAY,0BAA2BsQ,GAAUG,SAErE,OAAOH,EAAWE,CACtB,CACO,SAASE,EAAsB9G,EAAcb,GAChDa,EAAarD,KAAOqD,EAAarD,KAAKvN,KAAK0C,IAAS,IACzCA,EACHoC,SAAU,IACHpC,EAAOoC,YAEPiL,EAAiBlL,QAAO,CAAC9B,EAAK6J,KAC7B,MAAMyJ,EAAOzJ,EAAKqH,MAAM,KAClB0D,EAAUtB,EAAKuB,MACrB,IAAIf,EAAM9T,EACV,IAAK,MAAM8U,KAAOxB,EACdQ,EAAIgB,GAAOhB,EAAIgB,IAAQ,CAAC,EACxBhB,EAAMA,EAAIgB,GAGd,OADAhB,EAAIc,GAAW,KACR5U,CAAG,GACXL,EAAOoC,cAG1B,C","sources":["webpack://morpheus/./node_modules/@orama/orama/dist/components/algorithms.js","webpack://morpheus/./node_modules/@orama/orama/dist/components/cosine-similarity.js","webpack://morpheus/./node_modules/@orama/orama/dist/components/facets.js","webpack://morpheus/./node_modules/@orama/orama/dist/components/filters.js","webpack://morpheus/./node_modules/@orama/orama/dist/components/groups.js","webpack://morpheus/./node_modules/@orama/orama/dist/components/hooks.js","webpack://morpheus/./node_modules/@orama/orama/dist/components/internal-document-id-store.js","webpack://morpheus/./node_modules/@orama/orama/dist/components/tokenizer/languages.js","webpack://morpheus/./node_modules/@orama/orama/dist/errors.js","webpack://morpheus/./node_modules/@orama/orama/dist/methods/search-vector.js","webpack://morpheus/./node_modules/@orama/orama/dist/constants.js","webpack://morpheus/./node_modules/@orama/orama/dist/methods/search-hybrid.js","webpack://morpheus/./node_modules/@orama/orama/dist/methods/search.js","webpack://morpheus/./node_modules/@orama/orama/dist/methods/search-fulltext.js","webpack://morpheus/./node_modules/@orama/orama/dist/utils.js"],"sourcesContent":["import { createError } from '../errors.js';\nexport function prioritizeTokenScores(arrays, boost, threshold = 1, keywordsCount) {\n    if (boost === 0) {\n        throw createError('INVALID_BOOST_VALUE');\n    }\n    const tokenScoresMap = new Map();\n    const tokenKeywordsCountMap = new Map();\n    const mapsLength = arrays.length;\n    for(let i = 0; i < mapsLength; i++){\n        const arr = arrays[i];\n        const entriesLength = arr.length;\n        for(let j = 0; j < entriesLength; j++){\n            const [token, score] = arr[j];\n            const boostScore = score * boost;\n            const oldScore = tokenScoresMap.get(token);\n            if (oldScore !== undefined) {\n                tokenScoresMap.set(token, oldScore * 1.5 + boostScore);\n                tokenKeywordsCountMap.set(token, tokenKeywordsCountMap.get(token) + 1);\n            } else {\n                tokenScoresMap.set(token, boostScore);\n                tokenKeywordsCountMap.set(token, 1);\n            }\n        }\n    }\n    const tokenScores = [];\n    for (const tokenScoreEntry of tokenScoresMap.entries()){\n        tokenScores.push(tokenScoreEntry);\n    }\n    const results = tokenScores.sort((a, b)=>b[1] - a[1]);\n    // If threshold is 1, it means we will return all the results with at least one search term,\n    // prioritizig the ones that contains more search terms (fuzzy match)\n    if (threshold === 1) {\n        return results;\n    }\n    // Prepare keywords count tracking for threshold handling\n    const allResults = results.length;\n    const tokenKeywordsCount = [];\n    for (const tokenKeywordsCountEntry of tokenKeywordsCountMap.entries()){\n        tokenKeywordsCount.push(tokenKeywordsCountEntry);\n    }\n    // Find the index of the last result with all keywords.\n    // Note that since score is multipled by 1.5 any time the token is encountered in results it means\n    // that tokenScores and tokenKeywordsCount should always have the same order.\n    const keywordsPerToken = tokenKeywordsCount.sort((a, b)=>b[1] - a[1]);\n    let lastTokenWithAllKeywords = undefined;\n    for(let i = 0; i < allResults; i++){\n        if (keywordsPerToken[i][1] === keywordsCount) {\n            lastTokenWithAllKeywords = i;\n        } else {\n            break;\n        }\n    }\n    // If no results had all the keywords, either bail out earlier or normalize\n    if (typeof lastTokenWithAllKeywords === 'undefined') {\n        if (threshold === 0) {\n            return [];\n        }\n        lastTokenWithAllKeywords = 0;\n    }\n    // If threshold is 0, it means we will only return all the results that contains ALL the search terms (exact match)\n    if (threshold === 0) {\n        return results.slice(0, lastTokenWithAllKeywords + 1);\n    }\n    // If the threshold is between 0 and 1, we will return all the results that contains at least the threshold of search terms\n    // For example, if threshold is 0.5, we will return all the results that contains at least 50% of the search terms\n    // (fuzzy match with a minimum threshold)\n    const thresholdLength = lastTokenWithAllKeywords + Math.ceil(threshold * 100 * (results.length - lastTokenWithAllKeywords) / 100);\n    return results.slice(0, results.length + thresholdLength);\n}\nexport function BM25(tf, matchingCount, docsCount, fieldLength, averageFieldLength, BM25Params) {\n    const { k , b , d  } = BM25Params;\n    const idf = Math.log(1 + (docsCount - matchingCount + 0.5) / (matchingCount + 0.5));\n    return idf * (d + tf * (k + 1)) / (tf + k * (1 - b + b * fieldLength / averageFieldLength));\n}\n\n//# sourceMappingURL=algorithms.js.map","export function getMagnitude(vector, vectorLength) {\n    let magnitude = 0;\n    for(let i = 0; i < vectorLength; i++){\n        magnitude += vector[i] * vector[i];\n    }\n    return Math.sqrt(magnitude);\n}\n// @todo: Write plugins for Node and Browsers to use parallel computation for this function\nexport function findSimilarVectors(targetVector, vectors, length, threshold = 0.8) {\n    const targetMagnitude = getMagnitude(targetVector, length);\n    const similarVectors = [];\n    for (const [vectorId, [magnitude, vector]] of Object.entries(vectors)){\n        let dotProduct = 0;\n        for(let i = 0; i < length; i++){\n            dotProduct += targetVector[i] * vector[i];\n        }\n        const similarity = dotProduct / (targetMagnitude * magnitude);\n        if (similarity >= threshold) {\n            similarVectors.push([\n                vectorId,\n                similarity\n            ]);\n        }\n    }\n    return similarVectors.sort((a, b)=>b[1] - a[1]);\n}\n\n//# sourceMappingURL=cosine-similarity.js.map","import { createError } from '../errors.js';\nimport { getNested } from '../utils.js';\nfunction sortingPredicate(order = 'desc', a, b) {\n    if (order.toLowerCase() === 'asc') {\n        return a[1] - b[1];\n    } else {\n        return b[1] - a[1];\n    }\n}\nexport async function getFacets(orama, results, facetsConfig) {\n    const facets = {};\n    const allIDs = results.map(([id])=>id);\n    const allDocs = await orama.documentsStore.getMultiple(orama.data.docs, allIDs);\n    const facetKeys = Object.keys(facetsConfig);\n    const properties = await orama.index.getSearchablePropertiesWithTypes(orama.data.index);\n    for (const facet of facetKeys){\n        let values = {};\n        // Hack to guarantee the same order of ranges as specified by the user\n        // TODO: Revisit this once components land\n        if (properties[facet] === 'number') {\n            const { ranges  } = facetsConfig[facet];\n            const tmp = [];\n            for (const range of ranges){\n                tmp.push([\n                    `${range.from}-${range.to}`,\n                    0\n                ]);\n            }\n            values = Object.fromEntries(tmp);\n        }\n        facets[facet] = {\n            count: 0,\n            values\n        };\n    }\n    const allDocsLength = allDocs.length;\n    for(let i = 0; i < allDocsLength; i++){\n        const doc = allDocs[i];\n        for (const facet of facetKeys){\n            const facetValue = facet.includes('.') ? await getNested(doc, facet) : doc[facet];\n            const propertyType = properties[facet];\n            switch(propertyType){\n                case 'number':\n                    {\n                        const ranges = facetsConfig[facet].ranges;\n                        calculateNumberFacet(ranges, facets[facet].values, facetValue);\n                        break;\n                    }\n                case 'number[]':\n                    {\n                        const alreadyInsertedValues = new Set();\n                        const ranges = facetsConfig[facet].ranges;\n                        for (const v of facetValue){\n                            calculateNumberFacet(ranges, facets[facet].values, v, alreadyInsertedValues);\n                        }\n                        break;\n                    }\n                case 'boolean':\n                case 'enum':\n                case 'string':\n                    {\n                        calculateBooleanStringOrEnumFacet(facets[facet].values, facetValue, propertyType);\n                        break;\n                    }\n                case 'boolean[]':\n                case 'enum[]':\n                case 'string[]':\n                    {\n                        const alreadyInsertedValues = new Set();\n                        const innerType = propertyType === 'boolean[]' ? 'boolean' : 'string';\n                        for (const v of facetValue){\n                            calculateBooleanStringOrEnumFacet(facets[facet].values, v, innerType, alreadyInsertedValues);\n                        }\n                        break;\n                    }\n                default:\n                    throw createError('FACET_NOT_SUPPORTED', propertyType);\n            }\n        }\n    }\n    for (const facet of facetKeys){\n        // Count the number of values for each facet\n        facets[facet].count = Object.keys(facets[facet].values).length;\n        // Sort only string-based facets\n        if (properties[facet] === 'string') {\n            const stringFacetDefinition = facetsConfig;\n            facets[facet].values = Object.fromEntries(Object.entries(facets[facet].values).sort((a, b)=>sortingPredicate(stringFacetDefinition.sort, a, b)).slice(stringFacetDefinition.offset ?? 0, stringFacetDefinition.limit ?? 10));\n        }\n    }\n    return facets;\n}\nfunction calculateNumberFacet(ranges, values, facetValue, alreadyInsertedValues) {\n    for (const range of ranges){\n        const value = `${range.from}-${range.to}`;\n        if (alreadyInsertedValues && alreadyInsertedValues.has(value)) {\n            continue;\n        }\n        if (facetValue >= range.from && facetValue <= range.to) {\n            if (values[value] === undefined) {\n                values[value] = 1;\n            } else {\n                values[value]++;\n                if (alreadyInsertedValues) {\n                    alreadyInsertedValues.add(value);\n                }\n            }\n        }\n    }\n}\nfunction calculateBooleanStringOrEnumFacet(values, facetValue, propertyType, alreadyInsertedValues) {\n    // String or boolean based facets\n    const value = (facetValue === null || facetValue === void 0 ? void 0 : facetValue.toString()) ?? (propertyType === 'boolean' ? 'false' : '');\n    if (alreadyInsertedValues && alreadyInsertedValues.has(value)) {\n        return;\n    }\n    values[value] = (values[value] ?? 0) + 1;\n    if (alreadyInsertedValues) {\n        alreadyInsertedValues.add(value);\n    }\n}\n\n//# sourceMappingURL=facets.js.map","export function intersectFilteredIDs(filtered, lookedUp) {\n    const map = new Map();\n    const result = [];\n    for (const id of filtered){\n        map.set(id, true);\n    }\n    for (const [id, score] of lookedUp){\n        if (map.has(id)) {\n            result.push([\n                id,\n                score\n            ]);\n            map.delete(id);\n        }\n    }\n    return result;\n}\n\n//# sourceMappingURL=filters.js.map","import { createError } from '../errors.js';\nimport { getNested, intersect, safeArrayPush } from '../utils.js';\nimport { getDocumentIdFromInternalId } from './internal-document-id-store.js';\nconst DEFAULT_REDUCE = {\n    reducer: (_, acc, res, index)=>{\n        acc[index] = res;\n        return acc;\n    },\n    getInitialValue: (length)=>Array.from({\n            length\n        })\n};\nconst ALLOWED_TYPES = [\n    'string',\n    'number',\n    'boolean'\n];\nexport async function getGroups(orama, results, groupBy) {\n    const properties = groupBy.properties;\n    const propertiesLength = properties.length;\n    const schemaProperties = await orama.index.getSearchablePropertiesWithTypes(orama.data.index);\n    for(let i = 0; i < propertiesLength; i++){\n        const property = properties[i];\n        if (typeof schemaProperties[property] === 'undefined') {\n            throw createError('UNKNOWN_GROUP_BY_PROPERTY', property);\n        }\n        if (!ALLOWED_TYPES.includes(schemaProperties[property])) {\n            throw createError('INVALID_GROUP_BY_PROPERTY', property, ALLOWED_TYPES.join(', '), schemaProperties[property]);\n        }\n    }\n    const allIDs = results.map(([id])=>getDocumentIdFromInternalId(orama.internalDocumentIDStore, id));\n    // allDocs is already sorted by the sortBy algorithm\n    // We leverage on that to limit the number of documents returned\n    const allDocs = await orama.documentsStore.getMultiple(orama.data.docs, allIDs);\n    const allDocsLength = allDocs.length;\n    const returnedCount = groupBy.maxResult || Number.MAX_SAFE_INTEGER;\n    const listOfValues = [];\n    // We want to understand which documents have which values\n    // and group them by the property and values\n    const g = {};\n    for(let i = 0; i < propertiesLength; i++){\n        const groupByKey = properties[i];\n        const group = {\n            property: groupByKey,\n            perValue: {}\n        };\n        const values = new Set();\n        for(let j = 0; j < allDocsLength; j++){\n            const doc = allDocs[j];\n            const value = await getNested(doc, groupByKey);\n            // we don't want to consider undefined values\n            if (typeof value === 'undefined') {\n                continue;\n            }\n            const keyValue = typeof value !== 'boolean' ? value : '' + value;\n            if (typeof group.perValue[keyValue] === 'undefined') {\n                group.perValue[keyValue] = {\n                    indexes: [],\n                    count: 0\n                };\n            }\n            if (group.perValue[keyValue].count >= returnedCount) {\n                continue;\n            }\n            // We use the index to keep track of the original order\n            group.perValue[keyValue].indexes.push(j);\n            group.perValue[keyValue].count++;\n            values.add(value);\n        }\n        listOfValues.push(Array.from(values));\n        g[groupByKey] = group;\n    }\n    const combinations = calculateCombination(listOfValues);\n    const combinationsLength = combinations.length;\n    const groups = [];\n    for(let i = 0; i < combinationsLength; i++){\n        const combination = combinations[i];\n        const combinationLength = combination.length;\n        const group = {\n            values: [],\n            indexes: []\n        };\n        const indexes = [];\n        for(let j = 0; j < combinationLength; j++){\n            const value = combination[j];\n            const property = properties[j];\n            indexes.push(g[property].perValue[typeof value !== 'boolean' ? value : '' + value].indexes);\n            group.values.push(value);\n        }\n        // We leverage on the index to sort the results by the original order\n        group.indexes = intersect(indexes).sort((a, b)=>a - b);\n        // don't generate empty groups\n        if (group.indexes.length === 0) {\n            continue;\n        }\n        groups.push(group);\n    }\n    const groupsLength = groups.length;\n    const res = Array.from({\n        length: groupsLength\n    });\n    for(let i = 0; i < groupsLength; i++){\n        const group = groups[i];\n        const reduce = groupBy.reduce || DEFAULT_REDUCE;\n        const docs = group.indexes.map((index)=>{\n            return {\n                id: allIDs[index],\n                score: results[index][1],\n                document: allDocs[index]\n            };\n        });\n        const func = reduce.reducer.bind(null, group.values);\n        const initialValue = reduce.getInitialValue(group.indexes.length);\n        const aggregationValue = docs.reduce(func, initialValue);\n        res[i] = {\n            values: group.values,\n            result: aggregationValue\n        };\n    }\n    return res;\n}\nfunction calculateCombination(arrs, index = 0) {\n    if (index + 1 === arrs.length) return arrs[index].map((item)=>[\n            item\n        ]);\n    const head = arrs[index];\n    const c = calculateCombination(arrs, index + 1);\n    const combinations = [];\n    for (const value of head){\n        for (const combination of c){\n            const result = [\n                value\n            ];\n            safeArrayPush(result, combination);\n            combinations.push(result);\n        }\n    }\n    return combinations;\n}\n\n//# sourceMappingURL=groups.js.map","export const OBJECT_COMPONENTS = [\n    'tokenizer',\n    'index',\n    'documentsStore',\n    'sorter'\n];\nexport const FUNCTION_COMPONENTS = [\n    'validateSchema',\n    'getDocumentIndexId',\n    'getDocumentProperties',\n    'formatElapsedTime'\n];\nexport const SINGLE_OR_ARRAY_COMPONENTS = [];\nexport async function runSingleHook(hooks, orama, id, doc) {\n    const hooksLength = hooks.length;\n    for(let i = 0; i < hooksLength; i++){\n        await hooks[i](orama, id, doc);\n    }\n}\nexport async function runMultipleHook(hooks, orama, docsOrIds) {\n    const hooksLength = hooks.length;\n    for(let i = 0; i < hooksLength; i++){\n        await hooks[i](orama, docsOrIds);\n    }\n}\nexport async function runAfterSearch(hooks, db, params, language, results) {\n    const hooksLength = hooks.length;\n    for(let i = 0; i < hooksLength; i++){\n        await hooks[i](db, params, language, results);\n    }\n}\nexport async function runBeforeSearch(hooks, db, params, language) {\n    const hooksLength = hooks.length;\n    for(let i = 0; i < hooksLength; i++){\n        await hooks[i](db, params, language);\n    }\n}\n\n//# sourceMappingURL=hooks.js.map","export function createInternalDocumentIDStore() {\n    return {\n        idToInternalId: new Map(),\n        internalIdToId: [],\n        save,\n        load\n    };\n}\nexport function save(store) {\n    return {\n        internalIdToId: store.internalIdToId\n    };\n}\nexport function load(orama, raw) {\n    const { internalIdToId  } = raw;\n    orama.internalDocumentIDStore.idToInternalId.clear();\n    orama.internalDocumentIDStore.internalIdToId = [];\n    for(let i = 0; i < internalIdToId.length; i++){\n        orama.internalDocumentIDStore.idToInternalId.set(internalIdToId[i], i + 1);\n        orama.internalDocumentIDStore.internalIdToId.push(internalIdToId[i]);\n    }\n}\nexport function getInternalDocumentId(store, id) {\n    if (typeof id === 'string') {\n        const internalId = store.idToInternalId.get(id);\n        if (internalId) {\n            return internalId;\n        }\n        const currentId = store.idToInternalId.size + 1;\n        store.idToInternalId.set(id, currentId);\n        store.internalIdToId.push(id);\n        return currentId;\n    }\n    if (id > store.internalIdToId.length) {\n        return getInternalDocumentId(store, id.toString());\n    }\n    return id;\n}\nexport function getDocumentIdFromInternalId(store, internalId) {\n    if (store.internalIdToId.length < internalId) {\n        throw new Error(`Invalid internalId ${internalId}`);\n    }\n    return store.internalIdToId[internalId - 1];\n}\n\n//# sourceMappingURL=internal-document-id-store.js.map","export const STEMMERS = {\n    arabic: 'ar',\n    armenian: 'am',\n    bulgarian: 'bg',\n    danish: 'dk',\n    dutch: 'nl',\n    english: 'en',\n    finnish: 'fi',\n    french: 'fr',\n    german: 'de',\n    greek: 'gr',\n    hungarian: 'hu',\n    indian: 'in',\n    indonesian: 'id',\n    irish: 'ie',\n    italian: 'it',\n    lithuanian: 'lt',\n    nepali: 'np',\n    norwegian: 'no',\n    portuguese: 'pt',\n    romanian: 'ro',\n    russian: 'ru',\n    serbian: 'rs',\n    slovenian: 'ru',\n    spanish: 'es',\n    swedish: 'se',\n    tamil: 'ta',\n    turkish: 'tr',\n    ukrainian: 'uk',\n    sanskrit: 'sk'\n};\nexport const SPLITTERS = {\n    dutch: /[^A-Za-zàèéìòóù0-9_'-]+/gim,\n    english: /[^A-Za-zàèéìòóù0-9_'-]+/gim,\n    french: /[^a-z0-9äâàéèëêïîöôùüûœç-]+/gim,\n    italian: /[^A-Za-zàèéìòóù0-9_'-]+/gim,\n    norwegian: /[^a-z0-9_æøåÆØÅäÄöÖüÜ]+/gim,\n    portuguese: /[^a-z0-9à-úÀ-Ú]/gim,\n    russian: /[^a-z0-9а-яА-ЯёЁ]+/gim,\n    spanish: /[^a-z0-9A-Zá-úÁ-ÚñÑüÜ]+/gim,\n    swedish: /[^a-z0-9_åÅäÄöÖüÜ-]+/gim,\n    german: /[^a-z0-9A-ZäöüÄÖÜß]+/gim,\n    finnish: /[^a-z0-9äöÄÖ]+/gim,\n    danish: /[^a-z0-9æøåÆØÅ]+/gim,\n    hungarian: /[^a-z0-9áéíóöőúüűÁÉÍÓÖŐÚÜŰ]+/gim,\n    romanian: /[^a-z0-9ăâîșțĂÂÎȘȚ]+/gim,\n    serbian: /[^a-z0-9čćžšđČĆŽŠĐ]+/gim,\n    turkish: /[^a-z0-9çÇğĞıİöÖşŞüÜ]+/gim,\n    lithuanian: /[^a-z0-9ąčęėįšųūžĄČĘĖĮŠŲŪŽ]+/gim,\n    arabic: /[^a-z0-9أ-ي]+/gim,\n    nepali: /[^a-z0-9अ-ह]+/gim,\n    irish: /[^a-z0-9áéíóúÁÉÍÓÚ]+/gim,\n    indian: /[^a-z0-9अ-ह]+/gim,\n    armenian: /[^a-z0-9ա-ֆ]+/gim,\n    greek: /[^a-z0-9α-ωά-ώ]+/gim,\n    indonesian: /[^a-z0-9]+/gim,\n    ukrainian: /[^a-z0-9а-яА-ЯіїєІЇЄ]+/gim,\n    slovenian: /[^a-z0-9čžšČŽŠ]+/gim,\n    bulgarian: /[^a-z0-9а-яА-Я]+/gim,\n    tamil: /[^a-z0-9அ-ஹ]+/gim,\n    sanskrit: /[^a-z0-9A-Zāīūṛḷṃṁḥśṣṭḍṇṅñḻḹṝ]+/gim\n};\nexport const SUPPORTED_LANGUAGES = Object.keys(STEMMERS);\n\n//# sourceMappingURL=languages.js.map","import { SUPPORTED_LANGUAGES } from './components/tokenizer/languages.js';\nimport { sprintf } from './utils.js';\nconst allLanguages = SUPPORTED_LANGUAGES.join('\\n - ');\nconst errors = {\n    NO_LANGUAGE_WITH_CUSTOM_TOKENIZER: 'Do not pass the language option to create when using a custom tokenizer.',\n    LANGUAGE_NOT_SUPPORTED: `Language \"%s\" is not supported.\\nSupported languages are:\\n - ${allLanguages}`,\n    INVALID_STEMMER_FUNCTION_TYPE: `config.stemmer property must be a function.`,\n    MISSING_STEMMER: `As of version 1.0.0 @orama/orama does not ship non English stemmers by default. To solve this, please explicitly import and specify the \"%s\" stemmer from the package @orama/stemmers. See https://docs.oramasearch.com/open-source/text-analysis/stemming for more information.`,\n    CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY: 'Custom stop words array must only contain strings.',\n    UNSUPPORTED_COMPONENT: `Unsupported component \"%s\".`,\n    COMPONENT_MUST_BE_FUNCTION: `The component \"%s\" must be a function.`,\n    COMPONENT_MUST_BE_FUNCTION_OR_ARRAY_FUNCTIONS: `The component \"%s\" must be a function or an array of functions.`,\n    INVALID_SCHEMA_TYPE: `Unsupported schema type \"%s\" at \"%s\". Expected \"string\", \"boolean\" or \"number\" or array of them.`,\n    DOCUMENT_ID_MUST_BE_STRING: `Document id must be of type \"string\". Got \"%s\" instead.`,\n    DOCUMENT_ALREADY_EXISTS: `A document with id \"%s\" already exists.`,\n    DOCUMENT_DOES_NOT_EXIST: `A document with id \"%s\" does not exists.`,\n    MISSING_DOCUMENT_PROPERTY: `Missing searchable property \"%s\".`,\n    INVALID_DOCUMENT_PROPERTY: `Invalid document property \"%s\": expected \"%s\", got \"%s\"`,\n    UNKNOWN_INDEX: `Invalid property name \"%s\". Expected a wildcard string (\"*\") or array containing one of the following properties: %s`,\n    INVALID_BOOST_VALUE: `Boost value must be a number greater than, or less than 0.`,\n    INVALID_FILTER_OPERATION: `You can only use one operation per filter, you requested %d.`,\n    SCHEMA_VALIDATION_FAILURE: `Cannot insert document due schema validation failure on \"%s\" property.`,\n    INVALID_SORT_SCHEMA_TYPE: `Unsupported sort schema type \"%s\" at \"%s\". Expected \"string\" or \"number\".`,\n    CANNOT_SORT_BY_ARRAY: `Cannot configure sort for \"%s\" because it is an array (%s).`,\n    UNABLE_TO_SORT_ON_UNKNOWN_FIELD: `Unable to sort on unknown field \"%s\". Allowed fields: %s`,\n    SORT_DISABLED: `Sort is disabled. Please read the documentation at https://docs.oramasearch for more information.`,\n    UNKNOWN_GROUP_BY_PROPERTY: `Unknown groupBy property \"%s\".`,\n    INVALID_GROUP_BY_PROPERTY: `Invalid groupBy property \"%s\". Allowed types: \"%s\", but given \"%s\".`,\n    UNKNOWN_FILTER_PROPERTY: `Unknown filter property \"%s\".`,\n    INVALID_VECTOR_SIZE: `Vector size must be a number greater than 0. Got \"%s\" instead.`,\n    INVALID_VECTOR_VALUE: `Vector value must be a number greater than 0. Got \"%s\" instead.`,\n    INVALID_INPUT_VECTOR: `Property \"%s\" was declared as a %s-dimensional vector, but got a %s-dimensional vector instead.\\nInput vectors must be of the size declared in the schema, as calculating similarity between vectors of different sizes can lead to unexpected results.`,\n    WRONG_SEARCH_PROPERTY_TYPE: `Property \"%s\" is not searchable. Only \"string\" properties are searchable.`,\n    FACET_NOT_SUPPORTED: `Facet doens't support the type \"%s\".`,\n    INVALID_DISTANCE_SUFFIX: `Invalid distance suffix \"%s\". Valid suffixes are: cm, m, km, mi, yd, ft.`,\n    INVALID_SEARCH_MODE: `Invalid search mode \"%s\". Valid modes are: \"fulltext\", \"vector\", \"hybrid\".`,\n    MISSING_VECTOR_AND_SECURE_PROXY: `No vector was provided and no secure proxy was configured. Please provide a vector or configure an Orama Secure Proxy to perform hybrid search.`,\n    MISSING_TERM: `\"term\" is a required parameter when performing hybrid search. Please provide a search term.`,\n    INVALID_VECTOR_INPUT: `Invalid \"vector\" property. Expected an object with \"value\" and \"property\" properties, but got \"%s\" instead.`,\n    PLUGIN_CRASHED: `A plugin crashed during initialization. Please check the error message for more information:`\n};\nexport function createError(code, ...args) {\n    const error = new Error(sprintf(errors[code] ?? `Unsupported Orama Error code: ${code}`, ...args));\n    error.code = code;\n    if ('captureStackTrace' in Error.prototype) {\n        Error.captureStackTrace(error);\n    }\n    return error;\n}\n\n//# sourceMappingURL=errors.js.map","import { createSearchContext } from './search.js';\nimport { getNanosecondsTime, formatNanoseconds } from '../utils.js';\nimport { getFacets } from '../components/facets.js';\nimport { createError } from '../errors.js';\nimport { findSimilarVectors } from '../components/cosine-similarity.js';\nimport { intersectFilteredIDs } from '../components/filters.js';\nimport { getGroups } from '../components/groups.js';\nimport { getInternalDocumentId, getDocumentIdFromInternalId } from '../components/internal-document-id-store.js';\nimport { runBeforeSearch, runAfterSearch } from '../components/hooks.js';\nexport async function searchVector(orama, params, language = 'english') {\n    const timeStart = await getNanosecondsTime();\n    if (orama.beforeSearch) {\n        await runBeforeSearch(orama.beforeSearch, orama, params, language);\n    }\n    const { vector  } = params;\n    if (vector && (!('value' in vector) || !('property' in vector))) {\n        throw createError('INVALID_VECTOR_INPUT', Object.keys(vector).join(', '));\n    }\n    const { limit =10 , offset =0 , includeVectors =false  } = params;\n    const vectorIndex = orama.data.index.vectorIndexes[vector.property];\n    const vectorSize = vectorIndex.size;\n    const vectors = vectorIndex.vectors;\n    const shouldCalculateFacets = params.facets && Object.keys(params.facets).length > 0;\n    const hasFilters = Object.keys(params.where ?? {}).length > 0;\n    const { index , docs: oramaDocs  } = orama.data;\n    if ((vector === null || vector === void 0 ? void 0 : vector.value.length) !== vectorSize) {\n        // eslint-disable-next-line\n        throw createError('INVALID_INPUT_VECTOR', vector === null || vector === void 0 ? void 0 : vector.property, vectorSize, vector === null || vector === void 0 ? void 0 : vector.value.length);\n    }\n    if (!(vector instanceof Float32Array)) {\n        vector.value = new Float32Array(vector.value);\n    }\n    let results = findSimilarVectors(vector.value, vectors, vectorSize, params.similarity).map(([id, score])=>[\n            getInternalDocumentId(orama.internalDocumentIDStore, id),\n            score\n        ]);\n    let propertiesToSearch = orama.caches['propertiesToSearch'];\n    if (!propertiesToSearch) {\n        const propertiesToSearchWithTypes = await orama.index.getSearchablePropertiesWithTypes(index);\n        propertiesToSearch = await orama.index.getSearchableProperties(index);\n        propertiesToSearch = propertiesToSearch.filter((prop)=>propertiesToSearchWithTypes[prop].startsWith('string'));\n        orama.caches['propertiesToSearch'] = propertiesToSearch;\n    }\n    const tokens = [];\n    const context = await createSearchContext(orama.tokenizer, orama.index, orama.documentsStore, language, params, propertiesToSearch, tokens, await orama.documentsStore.count(oramaDocs), timeStart);\n    let whereFiltersIDs = [];\n    if (hasFilters) {\n        whereFiltersIDs = await orama.index.searchByWhereClause(context, index, params.where);\n        results = intersectFilteredIDs(whereFiltersIDs, results);\n    }\n    let facetsResults = [];\n    if (shouldCalculateFacets) {\n        // Populate facets if needed\n        const facets = await getFacets(orama, results, params.facets);\n        facetsResults = facets;\n    }\n    const docs = Array.from({\n        length: limit\n    });\n    for(let i = 0; i < limit; i++){\n        const result = results[i + offset];\n        if (!result) {\n            break;\n        }\n        const doc = orama.data.docs.docs[result[0]];\n        if (doc) {\n            if (!includeVectors) {\n                doc[vector.property] = null;\n            }\n            const newDoc = {\n                id: getDocumentIdFromInternalId(orama.internalDocumentIDStore, result[0]),\n                score: result[1],\n                document: doc\n            };\n            docs[i] = newDoc;\n        }\n    }\n    let groups = [];\n    if (params.groupBy) {\n        groups = await getGroups(orama, results, params.groupBy);\n    }\n    if (orama.afterSearch) {\n        await runAfterSearch(orama.afterSearch, orama, params, language, results);\n    }\n    const timeEnd = await getNanosecondsTime();\n    const elapsedTime = timeEnd - timeStart;\n    return {\n        count: results.length,\n        hits: docs.filter(Boolean),\n        elapsed: {\n            raw: Number(elapsedTime),\n            formatted: await formatNanoseconds(elapsedTime)\n        },\n        ...facetsResults ? {\n            facets: facetsResults\n        } : {},\n        ...groups ? {\n            groups\n        } : {}\n    };\n}\n\n//# sourceMappingURL=search-vector.js.map","export const MODE_FULLTEXT_SEARCH = 'fulltext';\nexport const MODE_HYBRID_SEARCH = 'hybrid';\nexport const MODE_VECTOR_SEARCH = 'vector';\n\n//# sourceMappingURL=constants.js.map","import { getNanosecondsTime, safeArrayPush, formatNanoseconds, removeVectorsFromHits } from '../utils.js';\nimport { intersectFilteredIDs } from '../components/filters.js';\nimport { prioritizeTokenScores } from '../components/algorithms.js';\nimport { createError } from '../errors.js';\nimport { createSearchContext, defaultBM25Params } from './search.js';\nimport { getFacets } from '../components/facets.js';\nimport { getGroups } from '../components/groups.js';\nimport { findSimilarVectors } from '../components/cosine-similarity.js';\nimport { getInternalDocumentId } from '../components/internal-document-id-store.js';\nimport { fetchDocuments } from './search.js';\nimport { runBeforeSearch, runAfterSearch } from '../components/hooks.js';\nexport async function hybridSearch(orama, params, language) {\n    const timeStart = await getNanosecondsTime();\n    if (orama.beforeSearch) {\n        await runBeforeSearch(orama.beforeSearch, orama, params, language);\n    }\n    const { offset =0 , limit =10 , includeVectors =false  } = params;\n    const shouldCalculateFacets = params.facets && Object.keys(params.facets).length > 0;\n    const [fullTextIDs, vectorIDs] = await Promise.all([\n        getFullTextSearchIDs(orama, params, language),\n        getVectorSearchIDs(orama, params)\n    ]);\n    const { index , docs  } = orama.data;\n    let uniqueTokenScores = mergeAndRankResults(fullTextIDs, vectorIDs, params.term ?? '');\n    // @todo avoid tokenize twice\n    const tokens = await orama.tokenizer.tokenize(params.term ?? '', language);\n    let propertiesToSearch = orama.caches['propertiesToSearch'];\n    if (!propertiesToSearch) {\n        const propertiesToSearchWithTypes = await orama.index.getSearchablePropertiesWithTypes(index);\n        propertiesToSearch = await orama.index.getSearchableProperties(index);\n        propertiesToSearch = propertiesToSearch.filter((prop)=>propertiesToSearchWithTypes[prop].startsWith('string'));\n        orama.caches['propertiesToSearch'] = propertiesToSearch;\n    }\n    if (params.properties && params.properties !== '*') {\n        for (const prop of params.properties){\n            if (!propertiesToSearch.includes(prop)) {\n                throw createError('UNKNOWN_INDEX', prop, propertiesToSearch.join(', '));\n            }\n        }\n        propertiesToSearch = propertiesToSearch.filter((prop)=>params.properties.includes(prop));\n    }\n    // @todo avoid create context twice\n    const context = await createSearchContext(orama.tokenizer, orama.index, orama.documentsStore, language, params, propertiesToSearch, tokens, await orama.documentsStore.count(docs), timeStart);\n    const hasFilters = Object.keys(params.where ?? {}).length > 0;\n    let whereFiltersIDs = [];\n    if (hasFilters) {\n        whereFiltersIDs = await orama.index.searchByWhereClause(context, index, params.where);\n        uniqueTokenScores = intersectFilteredIDs(whereFiltersIDs, uniqueTokenScores).slice(offset, offset + limit);\n    }\n    let facetsResults;\n    if (shouldCalculateFacets) {\n        const facets = await getFacets(orama, uniqueTokenScores, params.facets);\n        facetsResults = facets;\n    }\n    let groups;\n    if (params.groupBy) {\n        groups = await getGroups(orama, uniqueTokenScores, params.groupBy);\n    }\n    const results = (await fetchDocuments(orama, uniqueTokenScores, offset, limit)).filter(Boolean);\n    if (orama.afterSearch) {\n        await runAfterSearch(orama.afterSearch, orama, params, language, results);\n    }\n    const timeEnd = await getNanosecondsTime();\n    const returningResults = {\n        count: uniqueTokenScores.length,\n        elapsed: {\n            raw: Number(timeEnd - timeStart),\n            formatted: await formatNanoseconds(timeEnd - timeStart)\n        },\n        hits: results,\n        ...facetsResults ? {\n            facets: facetsResults\n        } : {},\n        ...groups ? {\n            groups\n        } : {}\n    };\n    if (!includeVectors) {\n        const vectorProperties = Object.keys(orama.data.index.vectorIndexes);\n        removeVectorsFromHits(returningResults, vectorProperties);\n    }\n    return returningResults;\n}\nasync function getFullTextSearchIDs(orama, params, language) {\n    const timeStart = await getNanosecondsTime();\n    params.relevance = Object.assign(params.relevance ?? {}, defaultBM25Params);\n    const { term , properties , threshold =1  } = params;\n    const { index , docs  } = orama.data;\n    const tokens = await orama.tokenizer.tokenize(term ?? '', language);\n    // Get searchable string properties\n    let propertiesToSearch = orama.caches['propertiesToSearch'];\n    if (!propertiesToSearch) {\n        const propertiesToSearchWithTypes = await orama.index.getSearchablePropertiesWithTypes(index);\n        propertiesToSearch = await orama.index.getSearchableProperties(index);\n        propertiesToSearch = propertiesToSearch.filter((prop)=>propertiesToSearchWithTypes[prop].startsWith('string'));\n        orama.caches['propertiesToSearch'] = propertiesToSearch;\n    }\n    if (properties && properties !== '*') {\n        for (const prop of properties){\n            if (!propertiesToSearch.includes(prop)) {\n                throw createError('UNKNOWN_INDEX', prop, propertiesToSearch.join(', '));\n            }\n        }\n        propertiesToSearch = propertiesToSearch.filter((prop)=>properties.includes(prop));\n    }\n    // Create the search context and the results\n    const context = await createSearchContext(orama.tokenizer, orama.index, orama.documentsStore, language, params, propertiesToSearch, tokens, await orama.documentsStore.count(docs), timeStart);\n    const tokensLength = tokens.length;\n    if (tokensLength || properties && properties.length > 0) {\n        // Now it's time to loop over all the indices and get the documents IDs for every single term\n        const indexesLength = propertiesToSearch.length;\n        for(let i = 0; i < indexesLength; i++){\n            var _params_boost;\n            const prop = propertiesToSearch[i];\n            if (tokensLength !== 0) {\n                for(let j = 0; j < tokensLength; j++){\n                    const term = tokens[j];\n                    // Lookup\n                    const scoreList = await orama.index.search(context, index, prop, term);\n                    safeArrayPush(context.indexMap[prop][term], scoreList);\n                }\n            } else {\n                context.indexMap[prop][''] = [];\n                const scoreList = await orama.index.search(context, index, prop, '');\n                safeArrayPush(context.indexMap[prop][''], scoreList);\n            }\n            const docIds = context.indexMap[prop];\n            const vals = Object.values(docIds);\n            context.docsIntersection[prop] = prioritizeTokenScores(vals, (params === null || params === void 0 ? void 0 : (_params_boost = params.boost) === null || _params_boost === void 0 ? void 0 : _params_boost[prop]) ?? 1, threshold, tokensLength);\n            const uniqueDocs = context.docsIntersection[prop];\n            const uniqueDocsLength = uniqueDocs.length;\n            for(let i = 0; i < uniqueDocsLength; i++){\n                const [id, score] = uniqueDocs[i];\n                const prevScore = context.uniqueDocsIDs[id];\n                if (prevScore) {\n                    context.uniqueDocsIDs[id] = prevScore + score + 0.5;\n                } else {\n                    context.uniqueDocsIDs[id] = score;\n                }\n            }\n        }\n    } else if (tokens.length === 0 && term) {\n        // This case is hard to handle correctly.\n        // For the time being, if tokenizer returns empty array but the term is not empty,\n        // we returns an empty result set\n        context.uniqueDocsIDs = {};\n    } else {\n        context.uniqueDocsIDs = Object.fromEntries(Object.keys(await orama.documentsStore.getAll(orama.data.docs)).map((k)=>[\n                k,\n                0\n            ]));\n    }\n    const uniqueIDs = Object.entries(context.uniqueDocsIDs).map(([id, score])=>[\n            +id,\n            score\n        ]).sort((a, b)=>b[1] - a[1]);\n    return minMaxScoreNormalization(uniqueIDs);\n}\nexport async function getVectorSearchIDs(orama, params) {\n    const vector = params.vector;\n    // eslint-disable-next-line @typescript-eslint/no-non-null-asserted-optional-chain\n    const vectorIndex = orama.data.index.vectorIndexes[vector === null || vector === void 0 ? void 0 : vector.property];\n    const vectorSize = vectorIndex.size;\n    const vectors = vectorIndex.vectors;\n    if (vector && (!vector.value || !vector.property)) {\n        throw createError('INVALID_VECTOR_INPUT', Object.keys(vector).join(', '));\n    }\n    if (vector.value.length !== vectorSize) {\n        throw createError('INVALID_INPUT_VECTOR', vector.property, vectorSize, vector.value.length);\n    }\n    if (!(vector instanceof Float32Array)) {\n        vector.value = new Float32Array(vector.value);\n    }\n    const uniqueIDs = findSimilarVectors(vector.value, vectors, vectorSize, params.similarity).map(([id, score])=>[\n            getInternalDocumentId(orama.internalDocumentIDStore, id),\n            score\n        ]);\n    return minMaxScoreNormalization(uniqueIDs);\n}\nfunction minMaxScoreNormalization(results) {\n    const maxScore = Math.max(...results.map(([, score])=>score));\n    return results.map(([id, score])=>[\n            id,\n            score / maxScore\n        ]);\n}\nfunction normalizeScore(score, maxScore) {\n    return score / maxScore;\n}\nfunction hybridScore(textScore, vectorScore, textWeight, vectorWeight) {\n    return textScore * textWeight + vectorScore * vectorWeight;\n}\nfunction mergeAndRankResults(textResults, vectorResults, query) {\n    const maxTextScore = Math.max(...textResults.map(([, score])=>score));\n    const maxVectorScore = Math.max(...vectorResults.map(([, score])=>score));\n    const { textWeight , vectorWeight  } = getQueryWeights(query);\n    const mergedResults = new Map();\n    const textResultsLength = textResults.length;\n    for(let i = 0; i < textResultsLength; i++){\n        const normalizedScore = normalizeScore(textResults[i][1], maxTextScore);\n        //                                                    ^ 1 here refers to \"score\"\n        const hybridScoreValue = hybridScore(normalizedScore, 0, textWeight, vectorWeight);\n        mergedResults.set(textResults[i][0], hybridScoreValue);\n    //                               ^ 0 here refers to \"id\"\n    }\n    const vectorResultsLength = vectorResults.length;\n    for(let i = 0; i < vectorResultsLength; i++){\n        const normalizedScore = normalizeScore(vectorResults[i][1], maxVectorScore);\n        //                                                      ^ 1 here refers to \"score\"\n        if (mergedResults.has(vectorResults[i][0])) {\n            let existingRes = mergedResults.get(vectorResults[i][0]);\n            //                                                   ^ 0 here refers to \"id\"\n            mergedResults.set(vectorResults[i][0], existingRes += hybridScore(0, normalizedScore, textWeight, vectorWeight));\n        //                                 ^ 0 here refers to \"id\"\n        } else {\n            mergedResults.set(vectorResults[i][0], hybridScore(0, normalizedScore, textWeight, vectorWeight));\n        //                                 ^ 0 here refers to \"id\"\n        }\n    }\n    return [\n        ...mergedResults\n    ].sort((a, b)=>b[1] - a[1]);\n}\n// eslint-disable-next-line @typescript-eslint/no-unused-vars\nfunction getQueryWeights(query) {\n    // In the next versions of Orama, we will ship a plugin containing a ML model to adjust the weights\n    // based on whether the query is keyword-focused, conceptual, etc.\n    // For now, we just return a fixed value.\n    return {\n        textWeight: 0.5,\n        vectorWeight: 0.5\n    };\n}\n\n//# sourceMappingURL=search-hybrid.js.map","import { getDocumentIdFromInternalId } from '../components/internal-document-id-store.js';\nimport { createError } from '../errors.js';\nimport { getNested } from '../utils.js';\nimport { MODE_FULLTEXT_SEARCH, MODE_HYBRID_SEARCH, MODE_VECTOR_SEARCH } from '../constants.js';\nimport { fullTextSearch } from './search-fulltext.js';\nimport { searchVector } from './search-vector.js';\nimport { hybridSearch } from './search-hybrid.js';\nexport const defaultBM25Params = {\n    k: 1.2,\n    b: 0.75,\n    d: 0.5\n};\nexport async function createSearchContext(tokenizer, index, documentsStore, language, params, properties, tokens, docsCount, timeStart) {\n    // If filters are enabled, we need to get the IDs of the documents that match the filters.\n    // const hasFilters = Object.keys(params.where ?? {}).length > 0;\n    // let whereFiltersIDs: string[] = [];\n    // if (hasFilters) {\n    //   whereFiltersIDs = getWhereFiltersIDs(params.where!, orama);\n    // }\n    // indexMap is an object containing all the indexes considered for the current search,\n    // and an array of doc IDs for each token in all the indices.\n    //\n    // Given the search term \"quick brown fox\" on the \"description\" index,\n    // indexMap will look like this:\n    //\n    // {\n    //   description: {\n    //     quick: [doc1, doc2, doc3],\n    //     brown: [doc2, doc4],\n    //     fox:   [doc2]\n    //   }\n    // }\n    const indexMap = {};\n    // After we create the indexMap, we need to calculate the intersection\n    // between all the postings lists for each token.\n    // Given the example above, docsIntersection will look like this:\n    //\n    // {\n    //   description: [doc2]\n    // }\n    //\n    // as doc2 is the only document present in all the postings lists for the \"description\" index.\n    const docsIntersection = {};\n    for (const prop of properties){\n        const tokensMap = {};\n        for (const token of tokens){\n            tokensMap[token] = [];\n        }\n        indexMap[prop] = tokensMap;\n        docsIntersection[prop] = [];\n    }\n    return {\n        timeStart,\n        tokenizer,\n        index,\n        documentsStore,\n        language,\n        params,\n        docsCount,\n        uniqueDocsIDs: {},\n        indexMap,\n        docsIntersection\n    };\n}\nexport async function search(orama, params, language) {\n    const mode = params.mode ?? MODE_FULLTEXT_SEARCH;\n    if (mode === MODE_FULLTEXT_SEARCH) {\n        return fullTextSearch(orama, params, language);\n    }\n    if (mode === MODE_VECTOR_SEARCH) {\n        return searchVector(orama, params);\n    }\n    if (mode === MODE_HYBRID_SEARCH) {\n        return hybridSearch(orama, params);\n    }\n    throw createError('INVALID_SEARCH_MODE', mode);\n}\nexport async function fetchDocumentsWithDistinct(orama, uniqueDocsArray, offset, limit, distinctOn) {\n    const docs = orama.data.docs;\n    // Keep track which values we already seen\n    const values = new Map();\n    // We cannot know how many results we will have in the end,\n    // so we need cannot pre-allocate the array.\n    const results = [];\n    const resultIDs = new Set();\n    const uniqueDocsArrayLength = uniqueDocsArray.length;\n    let count = 0;\n    for(let i = 0; i < uniqueDocsArrayLength; i++){\n        const idAndScore = uniqueDocsArray[i];\n        // If there are no more results, just break the loop\n        if (typeof idAndScore === 'undefined') {\n            continue;\n        }\n        const [id, score] = idAndScore;\n        if (resultIDs.has(id)) {\n            continue;\n        }\n        const doc = await orama.documentsStore.get(docs, id);\n        const value = await getNested(doc, distinctOn);\n        if (typeof value === 'undefined' || values.has(value)) {\n            continue;\n        }\n        values.set(value, true);\n        count++;\n        // We shouldn't consider the document if it's not in the offset range\n        if (count <= offset) {\n            continue;\n        }\n        results.push({\n            id: getDocumentIdFromInternalId(orama.internalDocumentIDStore, id),\n            score,\n            document: doc\n        });\n        resultIDs.add(id);\n        // reached the limit, break the loop\n        if (count >= offset + limit) {\n            break;\n        }\n    }\n    return results;\n}\nexport async function fetchDocuments(orama, uniqueDocsArray, offset, limit) {\n    const docs = orama.data.docs;\n    const results = Array.from({\n        length: limit\n    });\n    const resultIDs = new Set();\n    // We already have the list of ALL the document IDs containing the search terms.\n    // We loop over them starting from a positional value \"offset\" and ending at \"offset + limit\"\n    // to provide pagination capabilities to the search.\n    for(let i = offset; i < limit + offset; i++){\n        const idAndScore = uniqueDocsArray[i];\n        // If there are no more results, just break the loop\n        if (typeof idAndScore === 'undefined') {\n            break;\n        }\n        const [id, score] = idAndScore;\n        if (!resultIDs.has(id)) {\n            // We retrieve the full document only AFTER making sure that we really want it.\n            // We never retrieve the full document preventively.\n            const fullDoc = await orama.documentsStore.get(docs, id);\n            results[i] = {\n                id: getDocumentIdFromInternalId(orama.internalDocumentIDStore, id),\n                score,\n                document: fullDoc\n            };\n            resultIDs.add(id);\n        }\n    }\n    return results;\n}\n\n//# sourceMappingURL=search.js.map","import { getInternalDocumentId } from '../components/internal-document-id-store.js';\nimport { getNanosecondsTime, removeVectorsFromHits, safeArrayPush, sortTokenScorePredicate } from '../utils.js';\nimport { intersectFilteredIDs } from '../components/filters.js';\nimport { prioritizeTokenScores } from '../components/algorithms.js';\nimport { createError } from '../errors.js';\nimport { createSearchContext, defaultBM25Params, fetchDocumentsWithDistinct, fetchDocuments } from './search.js';\nimport { getFacets } from '../components/facets.js';\nimport { getGroups } from '../components/groups.js';\nimport { runBeforeSearch, runAfterSearch } from '../components/hooks.js';\nexport async function fullTextSearch(orama, params, language) {\n    const timeStart = await getNanosecondsTime();\n    if (orama.beforeSearch) {\n        await runBeforeSearch(orama.beforeSearch, orama, params, language);\n    }\n    params.relevance = Object.assign(params.relevance ?? {}, defaultBM25Params);\n    const vectorProperties = Object.keys(orama.data.index.vectorIndexes);\n    const shouldCalculateFacets = params.facets && Object.keys(params.facets).length > 0;\n    const { limit =10 , offset =0 , term , properties , threshold =1 , distinctOn , includeVectors =false  } = params;\n    const isPreflight = params.preflight === true;\n    const { index , docs  } = orama.data;\n    const tokens = await orama.tokenizer.tokenize(term ?? '', language);\n    // Get searchable string properties\n    let propertiesToSearch = orama.caches['propertiesToSearch'];\n    if (!propertiesToSearch) {\n        const propertiesToSearchWithTypes = await orama.index.getSearchablePropertiesWithTypes(index);\n        propertiesToSearch = await orama.index.getSearchableProperties(index);\n        propertiesToSearch = propertiesToSearch.filter((prop)=>propertiesToSearchWithTypes[prop].startsWith('string'));\n        orama.caches['propertiesToSearch'] = propertiesToSearch;\n    }\n    if (properties && properties !== '*') {\n        for (const prop of properties){\n            if (!propertiesToSearch.includes(prop)) {\n                throw createError('UNKNOWN_INDEX', prop, propertiesToSearch.join(', '));\n            }\n        }\n        propertiesToSearch = propertiesToSearch.filter((prop)=>properties.includes(prop));\n    }\n    // Create the search context and the results\n    const context = await createSearchContext(orama.tokenizer, orama.index, orama.documentsStore, language, params, propertiesToSearch, tokens, await orama.documentsStore.count(docs), timeStart);\n    // If filters are enabled, we need to get the IDs of the documents that match the filters.\n    const hasFilters = Object.keys(params.where ?? {}).length > 0;\n    let whereFiltersIDs = [];\n    if (hasFilters) {\n        whereFiltersIDs = await orama.index.searchByWhereClause(context, index, params.where);\n    }\n    const tokensLength = tokens.length;\n    if (tokensLength || properties && properties.length > 0) {\n        // Now it's time to loop over all the indices and get the documents IDs for every single term\n        const indexesLength = propertiesToSearch.length;\n        for(let i = 0; i < indexesLength; i++){\n            var _params_boost;\n            const prop = propertiesToSearch[i];\n            if (tokensLength !== 0) {\n                for(let j = 0; j < tokensLength; j++){\n                    const term = tokens[j];\n                    // Lookup\n                    const scoreList = await orama.index.search(context, index, prop, term);\n                    safeArrayPush(context.indexMap[prop][term], scoreList);\n                }\n            } else {\n                context.indexMap[prop][''] = [];\n                const scoreList = await orama.index.search(context, index, prop, '');\n                safeArrayPush(context.indexMap[prop][''], scoreList);\n            }\n            const docIds = context.indexMap[prop];\n            const vals = Object.values(docIds);\n            context.docsIntersection[prop] = prioritizeTokenScores(vals, (params === null || params === void 0 ? void 0 : (_params_boost = params.boost) === null || _params_boost === void 0 ? void 0 : _params_boost[prop]) ?? 1, threshold, tokensLength);\n            const uniqueDocs = context.docsIntersection[prop];\n            const uniqueDocsLength = uniqueDocs.length;\n            for(let i = 0; i < uniqueDocsLength; i++){\n                const [id, score] = uniqueDocs[i];\n                const prevScore = context.uniqueDocsIDs[id];\n                if (prevScore) {\n                    context.uniqueDocsIDs[id] = prevScore + score + 0.5;\n                } else {\n                    context.uniqueDocsIDs[id] = score;\n                }\n            }\n        }\n    } else if (tokens.length === 0 && term) {\n        // This case is hard to handle correctly.\n        // For the time being, if tokenizer returns empty array but the term is not empty,\n        // we returns an empty result set\n        context.uniqueDocsIDs = {};\n    } else {\n        context.uniqueDocsIDs = Object.fromEntries(Object.keys(await orama.documentsStore.getAll(orama.data.docs)).map((k)=>[\n                k,\n                0\n            ]));\n    }\n    // Get unique doc IDs from uniqueDocsIDs map\n    let uniqueDocsArray = Object.entries(context.uniqueDocsIDs).map(([id, score])=>[\n            +id,\n            score\n        ]);\n    // If filters are enabled, we need to remove the IDs of the documents that don't match the filters.\n    if (hasFilters) {\n        uniqueDocsArray = intersectFilteredIDs(whereFiltersIDs, uniqueDocsArray);\n    }\n    if (params.sortBy) {\n        if (typeof params.sortBy === 'function') {\n            const ids = uniqueDocsArray.map(([id])=>id);\n            const docs = await orama.documentsStore.getMultiple(orama.data.docs, ids);\n            const docsWithIdAndScore = docs.map((d, i)=>[\n                    uniqueDocsArray[i][0],\n                    uniqueDocsArray[i][1],\n                    d\n                ]);\n            docsWithIdAndScore.sort(params.sortBy);\n            uniqueDocsArray = docsWithIdAndScore.map(([id, score])=>[\n                    id,\n                    score\n                ]);\n        } else {\n            uniqueDocsArray = await orama.sorter.sortBy(orama.data.sorting, uniqueDocsArray, params.sortBy).then((results)=>results.map(([id, score])=>[\n                        getInternalDocumentId(orama.internalDocumentIDStore, id),\n                        score\n                    ]));\n        }\n    } else {\n        uniqueDocsArray = uniqueDocsArray.sort(sortTokenScorePredicate);\n    }\n    let results;\n    if (!isPreflight && distinctOn) {\n        results = await fetchDocumentsWithDistinct(orama, uniqueDocsArray, offset, limit, distinctOn);\n    } else if (!isPreflight) {\n        results = await fetchDocuments(orama, uniqueDocsArray, offset, limit);\n    }\n    const searchResult = {\n        elapsed: {\n            formatted: '',\n            raw: 0\n        },\n        // We keep the hits array empty if it's a preflight request.\n        hits: [],\n        count: uniqueDocsArray.length\n    };\n    if (typeof results !== 'undefined') {\n        searchResult.hits = results.filter(Boolean);\n        // Vectors can be very large, so we remove them from the result if not needed\n        if (!includeVectors) {\n            removeVectorsFromHits(searchResult, vectorProperties);\n        }\n    }\n    if (shouldCalculateFacets) {\n        // Populate facets if needed\n        const facets = await getFacets(orama, uniqueDocsArray, params.facets);\n        searchResult.facets = facets;\n    }\n    if (params.groupBy) {\n        searchResult.groups = await getGroups(orama, uniqueDocsArray, params.groupBy);\n    }\n    if (orama.afterSearch) {\n        await runAfterSearch(orama.afterSearch, orama, params, language, searchResult);\n    }\n    // Calculate elapsed time only at the end of the function\n    searchResult.elapsed = await orama.formatElapsedTime(await getNanosecondsTime() - context.timeStart);\n    return searchResult;\n}\n\n//# sourceMappingURL=search-fulltext.js.map","import { createError } from './errors.js';\nconst baseId = Date.now().toString().slice(5);\nlet lastId = 0;\nconst k = 1024;\nconst nano = BigInt(1e3);\nconst milli = BigInt(1e6);\nconst second = BigInt(1e9);\nexport const isServer = typeof window === 'undefined';\n/**\n * This value can be increased up to 100_000\n * But i don't know if this value change from nodejs to nodejs\n * So I will keep a safer value here.\n */ export const MAX_ARGUMENT_FOR_STACK = 65535;\n/**\n * This method is needed to used because of issues like: https://github.com/oramasearch/orama/issues/301\n * that issue is caused because the array that is pushed is huge (>100k)\n *\n * @example\n * ```ts\n * safeArrayPush(myArray, [1, 2])\n * ```\n */ export function safeArrayPush(arr, newArr) {\n    if (newArr.length < MAX_ARGUMENT_FOR_STACK) {\n        Array.prototype.push.apply(arr, newArr);\n    } else {\n        for(let i = 0; i < newArr.length; i += MAX_ARGUMENT_FOR_STACK){\n            Array.prototype.push.apply(arr, newArr.slice(i, i + MAX_ARGUMENT_FOR_STACK));\n        }\n    }\n}\nexport function sprintf(template, ...args) {\n    return template.replace(/%(?:(?<position>\\d+)\\$)?(?<width>-?\\d*\\.?\\d*)(?<type>[dfs])/g, function(...replaceArgs) {\n        const groups = replaceArgs[replaceArgs.length - 1];\n        const { width: rawWidth , type , position  } = groups;\n        const replacement = position ? args[Number.parseInt(position) - 1] : args.shift();\n        const width = rawWidth === '' ? 0 : Number.parseInt(rawWidth);\n        switch(type){\n            case 'd':\n                return replacement.toString().padStart(width, '0');\n            case 'f':\n                {\n                    let value = replacement;\n                    const [padding, precision] = rawWidth.split('.').map((w)=>Number.parseFloat(w));\n                    if (typeof precision === 'number' && precision >= 0) {\n                        value = value.toFixed(precision);\n                    }\n                    return typeof padding === 'number' && padding >= 0 ? value.toString().padStart(width, '0') : value.toString();\n                }\n            case 's':\n                return width < 0 ? replacement.toString().padEnd(-width, ' ') : replacement.toString().padStart(width, ' ');\n            default:\n                return replacement;\n        }\n    });\n}\nexport async function formatBytes(bytes, decimals = 2) {\n    if (bytes === 0) {\n        return '0 Bytes';\n    }\n    const dm = decimals < 0 ? 0 : decimals;\n    const sizes = [\n        'Bytes',\n        'KB',\n        'MB',\n        'GB',\n        'TB',\n        'PB',\n        'EB',\n        'ZB',\n        'YB'\n    ];\n    const i = Math.floor(Math.log(bytes) / Math.log(k));\n    return `${parseFloat((bytes / Math.pow(k, i)).toFixed(dm))} ${sizes[i]}`;\n}\nexport function isInsideWebWorker() {\n    // @ts-expect-error - WebWorker global scope\n    return typeof WorkerGlobalScope !== 'undefined' && self instanceof WorkerGlobalScope;\n}\nexport function isInsideNode() {\n    return typeof process !== 'undefined' && process.release && process.release.name === 'node';\n}\nexport function getNanosecondTimeViaPerformance() {\n    return BigInt(Math.floor(performance.now() * 1e6));\n}\nexport async function formatNanoseconds(value) {\n    if (typeof value === 'number') {\n        value = BigInt(value);\n    }\n    if (value < nano) {\n        return `${value}ns`;\n    } else if (value < milli) {\n        return `${value / nano}μs`;\n    } else if (value < second) {\n        return `${value / milli}ms`;\n    }\n    return `${value / second}s`;\n}\nexport async function getNanosecondsTime() {\n    if (isInsideWebWorker()) {\n        return getNanosecondTimeViaPerformance();\n    }\n    if (isInsideNode()) {\n        return process.hrtime.bigint();\n    }\n    if (typeof process !== 'undefined' && process.hrtime !== undefined) {\n        return process.hrtime.bigint();\n    }\n    if (typeof performance !== 'undefined') {\n        return getNanosecondTimeViaPerformance();\n    }\n    // @todo: fallback to V8 native method to get microtime\n    return BigInt(0);\n}\nexport async function uniqueId() {\n    return `${baseId}-${lastId++}`;\n}\nexport function getOwnProperty(object, property) {\n    // Checks if `hasOwn` method is defined avoiding errors with older Node.js versions\n    if (Object.hasOwn === undefined) {\n        return Object.prototype.hasOwnProperty.call(object, property) ? object[property] : undefined;\n    }\n    return Object.hasOwn(object, property) ? object[property] : undefined;\n}\nexport function getTokenFrequency(token, tokens) {\n    let count = 0;\n    for (const t of tokens){\n        if (t === token) {\n            count++;\n        }\n    }\n    return count;\n}\nexport function insertSortedValue(arr, el, compareFn = sortTokenScorePredicate) {\n    let low = 0;\n    let high = arr.length;\n    let mid;\n    while(low < high){\n        mid = low + high >>> 1;\n        if (compareFn(el, arr[mid]) < 0) {\n            high = mid;\n        } else {\n            low = mid + 1;\n        }\n    }\n    arr.splice(low, 0, el);\n    return arr;\n}\nexport function sortTokenScorePredicate(a, b) {\n    if (b[1] === a[1]) {\n        return a[0] - b[0];\n    }\n    return b[1] - a[1];\n}\n// Intersection function taken from https://github.com/lovasoa/fast_array_intersect.\n// MIT Licensed at the time of writing.\nexport function intersect(arrays) {\n    if (arrays.length === 0) {\n        return [];\n    } else if (arrays.length === 1) {\n        return arrays[0];\n    }\n    for(let i = 1; i < arrays.length; i++){\n        if (arrays[i].length < arrays[0].length) {\n            const tmp = arrays[0];\n            arrays[0] = arrays[i];\n            arrays[i] = tmp;\n        }\n    }\n    const set = new Map();\n    for (const elem of arrays[0]){\n        set.set(elem, 1);\n    }\n    for(let i = 1; i < arrays.length; i++){\n        let found = 0;\n        for (const elem of arrays[i]){\n            const count = set.get(elem);\n            if (count === i) {\n                set.set(elem, count + 1);\n                found++;\n            }\n        }\n        if (found === 0) return [];\n    }\n    return arrays[0].filter((e)=>{\n        const count = set.get(e);\n        if (count !== undefined) set.set(e, 0);\n        return count === arrays.length;\n    });\n}\nexport async function getDocumentProperties(doc, paths) {\n    const properties = {};\n    const pathsLength = paths.length;\n    for(let i = 0; i < pathsLength; i++){\n        const path = paths[i];\n        const pathTokens = path.split('.');\n        let current = doc;\n        const pathTokensLength = pathTokens.length;\n        for(let j = 0; j < pathTokensLength; j++){\n            current = current[pathTokens[j]];\n            // We found an object but we were supposed to be done\n            if (typeof current === 'object') {\n                if (current !== null && 'lat' in current && 'lon' in current && typeof current.lat === 'number' && typeof current.lon === 'number') {\n                    current = properties[path] = current;\n                    break;\n                } else if (!Array.isArray(current) && current !== null && j === pathTokensLength - 1) {\n                    current = undefined;\n                    break;\n                }\n            } else if ((current === null || typeof current !== 'object') && j < pathTokensLength - 1) {\n                // We can't recurse anymore but we were supposed to\n                current = undefined;\n                break;\n            }\n        }\n        if (typeof current !== 'undefined') {\n            properties[path] = current;\n        }\n    }\n    return properties;\n}\nexport async function getNested(obj, path) {\n    const props = await getDocumentProperties(obj, [\n        path\n    ]);\n    return props[path];\n}\nexport function flattenObject(obj, prefix = '') {\n    const result = {};\n    for(const key in obj){\n        const prop = `${prefix}${key}`;\n        const objKey = obj[key];\n        if (typeof objKey === 'object' && objKey !== null) {\n            Object.assign(result, flattenObject(objKey, `${prop}.`));\n        } else {\n            result[prop] = objKey;\n        }\n    }\n    return result;\n}\nconst mapDistanceToMeters = {\n    cm: 0.01,\n    m: 1,\n    km: 1000,\n    ft: 0.3048,\n    yd: 0.9144,\n    mi: 1609.344\n};\nexport function convertDistanceToMeters(distance, unit) {\n    const ratio = mapDistanceToMeters[unit];\n    if (ratio === undefined) {\n        throw new Error(createError('INVALID_DISTANCE_SUFFIX', distance).message);\n    }\n    return distance * ratio;\n}\nexport function removeVectorsFromHits(searchResult, vectorProperties) {\n    searchResult.hits = searchResult.hits.map((result)=>({\n            ...result,\n            document: {\n                ...result.document,\n                // Remove embeddings from the result\n                ...vectorProperties.reduce((acc, prop)=>{\n                    const path = prop.split('.');\n                    const lastKey = path.pop();\n                    let obj = acc;\n                    for (const key of path){\n                        obj[key] = obj[key] ?? {};\n                        obj = obj[key];\n                    }\n                    obj[lastKey] = null;\n                    return acc;\n                }, result.document)\n            }\n        }));\n}\n\n//# sourceMappingURL=utils.js.map"],"names":["prioritizeTokenScores","arrays","boost","threshold","keywordsCount","tokenScoresMap","Map","tokenKeywordsCountMap","mapsLength","length","i","arr","entriesLength","j","token","score","boostScore","oldScore","get","undefined","set","tokenScores","tokenScoreEntry","entries","push","results","sort","a","b","allResults","tokenKeywordsCount","tokenKeywordsCountEntry","keywordsPerToken","lastTokenWithAllKeywords","slice","thresholdLength","Math","ceil","BM25","tf","matchingCount","docsCount","fieldLength","averageFieldLength","BM25Params","k","d","log","getMagnitude","vector","vectorLength","magnitude","sqrt","findSimilarVectors","targetVector","vectors","targetMagnitude","similarVectors","vectorId","Object","dotProduct","similarity","sortingPredicate","order","toLowerCase","async","getFacets","orama","facetsConfig","facets","allIDs","map","id","allDocs","documentsStore","getMultiple","data","docs","facetKeys","keys","properties","index","getSearchablePropertiesWithTypes","facet","values","ranges","tmp","range","from","to","fromEntries","count","allDocsLength","doc","facetValue","includes","propertyType","calculateNumberFacet","alreadyInsertedValues","Set","v","calculateBooleanStringOrEnumFacet","innerType","stringFacetDefinition","offset","limit","value","has","add","toString","intersectFilteredIDs","filtered","lookedUp","result","delete","DEFAULT_REDUCE","reducer","_","acc","res","getInitialValue","Array","ALLOWED_TYPES","getGroups","groupBy","propertiesLength","schemaProperties","property","join","internalDocumentIDStore","returnedCount","maxResult","Number","MAX_SAFE_INTEGER","listOfValues","g","groupByKey","group","perValue","keyValue","indexes","combinations","calculateCombination","combinationsLength","groups","combination","combinationLength","groupsLength","reduce","document","func","bind","initialValue","aggregationValue","arrs","item","head","c","OBJECT_COMPONENTS","FUNCTION_COMPONENTS","runSingleHook","hooks","hooksLength","runMultipleHook","docsOrIds","runAfterSearch","db","params","language","runBeforeSearch","createInternalDocumentIDStore","idToInternalId","internalIdToId","save","load","store","raw","clear","getInternalDocumentId","internalId","currentId","size","getDocumentIdFromInternalId","Error","SPLITTERS","dutch","english","french","italian","norwegian","portuguese","russian","spanish","swedish","german","finnish","danish","hungarian","romanian","serbian","turkish","lithuanian","arabic","nepali","irish","indian","armenian","greek","indonesian","ukrainian","slovenian","bulgarian","tamil","sanskrit","SUPPORTED_LANGUAGES","errors","NO_LANGUAGE_WITH_CUSTOM_TOKENIZER","LANGUAGE_NOT_SUPPORTED","INVALID_STEMMER_FUNCTION_TYPE","MISSING_STEMMER","CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY","UNSUPPORTED_COMPONENT","COMPONENT_MUST_BE_FUNCTION","COMPONENT_MUST_BE_FUNCTION_OR_ARRAY_FUNCTIONS","INVALID_SCHEMA_TYPE","DOCUMENT_ID_MUST_BE_STRING","DOCUMENT_ALREADY_EXISTS","DOCUMENT_DOES_NOT_EXIST","MISSING_DOCUMENT_PROPERTY","INVALID_DOCUMENT_PROPERTY","UNKNOWN_INDEX","INVALID_BOOST_VALUE","INVALID_FILTER_OPERATION","SCHEMA_VALIDATION_FAILURE","INVALID_SORT_SCHEMA_TYPE","CANNOT_SORT_BY_ARRAY","UNABLE_TO_SORT_ON_UNKNOWN_FIELD","SORT_DISABLED","UNKNOWN_GROUP_BY_PROPERTY","INVALID_GROUP_BY_PROPERTY","UNKNOWN_FILTER_PROPERTY","INVALID_VECTOR_SIZE","INVALID_VECTOR_VALUE","INVALID_INPUT_VECTOR","WRONG_SEARCH_PROPERTY_TYPE","FACET_NOT_SUPPORTED","INVALID_DISTANCE_SUFFIX","INVALID_SEARCH_MODE","MISSING_VECTOR_AND_SECURE_PROXY","MISSING_TERM","INVALID_VECTOR_INPUT","PLUGIN_CRASHED","createError","code","args","error","prototype","captureStackTrace","searchVector","timeStart","beforeSearch","includeVectors","vectorIndex","vectorIndexes","vectorSize","shouldCalculateFacets","hasFilters","where","oramaDocs","Float32Array","propertiesToSearch","caches","propertiesToSearchWithTypes","getSearchableProperties","filter","prop","startsWith","context","createSearchContext","tokenizer","whereFiltersIDs","searchByWhereClause","facetsResults","newDoc","afterSearch","elapsedTime","hits","Boolean","elapsed","formatted","MODE_FULLTEXT_SEARCH","MODE_HYBRID_SEARCH","MODE_VECTOR_SEARCH","getFullTextSearchIDs","relevance","assign","defaultBM25Params","term","tokens","tokenize","tokensLength","indexesLength","_params_boost","scoreList","search","indexMap","docIds","vals","docsIntersection","uniqueDocs","uniqueDocsLength","prevScore","uniqueDocsIDs","getAll","minMaxScoreNormalization","getVectorSearchIDs","maxScore","max","normalizeScore","hybridScore","textScore","vectorScore","textWeight","vectorWeight","tokensMap","mode","vectorProperties","distinctOn","isPreflight","preflight","uniqueDocsArray","sortBy","ids","docsWithIdAndScore","sorter","sorting","then","fetchDocumentsWithDistinct","fetchDocuments","searchResult","formatElapsedTime","fullTextSearch","fullTextIDs","vectorIDs","Promise","all","uniqueTokenScores","textResults","vectorResults","query","maxTextScore","maxVectorScore","mergedResults","textResultsLength","hybridScoreValue","vectorResultsLength","normalizedScore","existingRes","mergeAndRankResults","timeEnd","returningResults","hybridSearch","resultIDs","uniqueDocsArrayLength","idAndScore","fullDoc","baseId","Date","now","lastId","nano","BigInt","milli","second","MAX_ARGUMENT_FOR_STACK","safeArrayPush","newArr","apply","sprintf","template","replace","replaceArgs","width","rawWidth","type","position","replacement","parseInt","shift","padStart","padding","precision","split","w","parseFloat","toFixed","padEnd","formatBytes","bytes","decimals","dm","floor","pow","getNanosecondTimeViaPerformance","performance","formatNanoseconds","getNanosecondsTime","WorkerGlobalScope","self","process","release","name","hrtime","bigint","uniqueId","getOwnProperty","object","hasOwn","hasOwnProperty","call","sortTokenScorePredicate","intersect","elem","found","e","getDocumentProperties","paths","pathsLength","path","pathTokens","current","pathTokensLength","lat","lon","isArray","getNested","obj","mapDistanceToMeters","cm","m","km","ft","yd","mi","convertDistanceToMeters","distance","unit","ratio","message","removeVectorsFromHits","lastKey","pop","key"],"sourceRoot":""}